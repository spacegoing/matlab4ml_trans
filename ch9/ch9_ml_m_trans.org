#+LATEX_HEADER: \usepackage{ctex}
#+LATEX_COMPILER: xelatex


* 第九章：机器学习实战

在第一章，MATLAB机器学习初步中我们谈到过，最基础的机器学习算法是
通过人工标注后的样本进行学习的，例如对分类问题，在数据集中研究人
员已经对每个样本属于哪个类别标注了分类标签，机器学习算法通过学习
这些样本，从中拟合出相应的分类边界，即识别出每种类型的模式。这与
最直观的人类学习的方法是相同的，粗略地讲人们也是通过不断重复学习
样例从中总结归纳经验知识。

前面的八个章节中我们已经研究了多种机器学习算法，现在是时候将它们
应用到实际数据集上了。最后一章作为全书的总结，我会以非常精简的语
言带领大家应用目前学习到的多种机器学习技术。你将看到我是如何使用
回归、分类、聚类等算法解决实际问题的。我们将把之前学到的诸多概念
应用于实际当中。当我需要帮助读者强化、回忆这些概念时，我会进行简
要地回顾。我们将试图尽可能多地采取各种方法，对真实数据集进行最大
程度的学习。

本章将会引导读者解决真实世界中的你和问题。你将会学习如何使
用'anns_snp'解决分类问题。最后我们将进行聚类分析。通过这种方式我
们能够同时回顾之前的学习过的两类，监督和非监督学习方法。

我们将会讲述一下主题：

- 拟合数据
- 模式识别
- 聚类分析

在本章结尾，我们将理解如何针对一系列的问题的具体情景、数据集的具
体特征，选用合适的拟合、模式识别和聚类分析算法。我们将会学习如何
为MATLAB的机器学习工具箱进行数据预处理。我们将看到MATLAB中提供了
哪些拟合、模式识别和聚类分析工具，以及如何使用这些工具完成数据预
处理、模型建立、模型拟合、模型评估、结果可视化和提高算法计算效率。


** DONE 预测混凝土质量
CLOSED: [2018-01-29 Mon 19:45]

在土木工程中，混凝土是构建建筑物最基本的材料。它可承受的强度与其
寿命、制造所使用的材料、测试时的温度等因素息息相关，是高度非线性
的。混凝土的制造过程十分复杂，涉及到多种材料进行制造，例如水泥、
熔炉产出的煤渣和灰烬、水、强度塑化剂、粗聚合剂、细聚合剂等化工原
料。对混凝土承重能力指标的采集使用了一个压力达 $2000kN$ 的液压测
试机，对混凝土方块或圆柱体进行压力测试。这个测试是破坏性的测试，
并且可能会持续很长时间，因此如果我们能够脱离实际测试，直接使用其
制作原料对其承重能力进行预测，将具备非常高的商业价值。下图显示了
一次承重力测试：

#+BEGIN_QUOTE
图9.1：承重能力测试
#+END_QUOTE

在本次研究中我们希望能够建立出一个以混凝土制作配方为输入数据，能
够预测其承重能力的模型。首先我们需要从'uci_snp'中获取数据集。

#+BEGIN_QUOTE
小贴士：读者可以通过如下链接

https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/

从'uci_snp'中下载数据集及其简短描述。
#+END_QUOTE

为了通过混凝土配方预测其成品的承重强度，数据集中已经采集了大量样
本数据，每个样本都包含 $8$ 个特征值作为输入数据，其输出值就是承重
强度指标。

本数据集包含了如下指标（按照数据集中特征值顺序排列），其中输入指
标包含：

- ~Cement~ 单位： $kg\text{/}m^3$
- ~Blast Furnace Slag~ 单位： $kg\text{/}m^3$
- ~Fly Ash~ 单位： $kg\text{/}m^3$
- ~Water~ 单位： $kg\text{/}m^3$
- ~Coarse Aggregate~ 单位： $kg\text{/}m^3$
- ~Fine Aggregate~ 单位： $kg\text{/}m^3$
- ~Age~ 单位： $kg\text{/}m^3$

输出指标包含：

- ~Concrete compressive strength~ 单位： $Mpa$

在从前面的地址下载完成 ~Concrete_Data.xls~ 文件后，确保这个文件是
保存在MATLAB的当前工作文件夹下，否则函数将会找不到这个文件。现在
我们通过MATLAB提供的数据处理组件 *Import Wizard* 将原始数据集导入
MATLAB。对于初学者而言 *Import Wizard* 非常有用，它能够通过对数据
进行可视化，大大简化我们导入数据、定义数据格式的流程，并提供了多
种导入方法。这个工具能够一步步地引导你完成数据的导入流程。通过这
个工具，我们能够导入多种格式的数据集。这个工具同时具备强大的可视
化功能，不仅能够展示数据集中的具体数值，还能允许我们选择导入哪些
变量、变量名是什么、哪些变量不予导入等。

我们通过如下步骤导入 ~Concrete_Data.xls~ ：

1. 点击 *Import Data* 按钮打开 *Import Wizard* 对话框
2. 在选择好要导入的数据文件后（我们这里选择 ~Concrete_Data.xls~
   ），一个名为 *Import Tool* 的新对话框将会打开。下图显示了需要
   点击的 *Import Data* 按钮和 *Import Tool* 对话窗口

#+BEGIN_QUOTE
图9.2：数据导入窗口
#+END_QUOTE

3. *Import Tool* 窗口中对 ~Concrete_Data.xls~ 文件中的数据进行了
   可视化处理，通过这个界面我们能够告诉数据导入工具，哪些变量需要
   被导入，那些不需要，或者直接导入全部数据
4. 在 *Import Data* 区域中的 *Output Type* 选项下有一个下拉菜单，
   通过这里我们能够选择我们需要保存的数据的变量类型。可选的选项有：
   *Table* 、 *Column vectors* 、 *Numeric Matrix* 、 *String
   Array* 、 *Cell*
5. 这里我们选择 *Column vectors*
6. 现在我们点击图9.2中 *Import Selection* 按钮，现在全部数据就会
   被这个非常好用的工具导入到我们的工作空间中了

在图9.2的第四步中，我们选择了 *Table* 类型作为导入数据类型，现在
我们看下这种选项会有怎样的数据结果被导入。重复之前的操作并选择
*Table* 作为导入类型，我们可以看到一个名为 ~ConcreteData~ 类型为
~table~ 的变量已经存在于工作空间中。我们可以通过鼠标点击打开对这
个变量的预览表格。如我们所期望的，这个变量的大小是 $1030 \times 9$
即其中包含了 $1030$ 个样本，和 $9$ 个变量（ $9$ 列）。每个样本有
$8$ 个混凝土原料配方作为输入特征值（前八列）及 $1$ 个目标值（最后
一列，承重能力）。数据集如下图所示：

#+BEGIN_QUOTE
图9.3： ~ConcreteData~ 数据集展示
#+END_QUOTE

导入工具同时为这些特征值和目标值创建了列名，这些列名使用的就是原
Excel文件中的表头名称。与之前预期相同，通过粗略观察我们已经可以看
到混凝土承重能力与其配方中的原料比例呈高度非线性的关系。我们来具
体看下这个数据集的基本统计指标，我们可以对 ~table~ 类型的变量直接
使用 ~summary()~ 函数完成这项工作：

#+BEGIN_QUOTE
代码
#+END_QUOTE

我们首先注意到，与之前数据集不同，这个数据集没有缺失值，因此我们
可以跳过之前的对缺失值预处理的步骤，直接进行第二步。接着我们对数
据集进行可视化处理，这个步骤在整个机器学习算法的应用流程中非常重
要。通过选择合适的图表类型进行绘制、对数据集的粗略观察，得到对数
据本身、数据间相关性的粗略认知非常重要，可以更好地帮助我们判断数
据集的特性，其可能的适应的模型、甚至可能选取的参数范围。这些知识
能够在相当大的程度上帮助我们简化建模流程、提高模型的准确率。对于
混凝土数据集，我们首先将以承重能力作为纵轴，特征值作为横轴，绘制
其每个样本 $8$ 个特征值的散点图矩阵。首先我们需要将 ~table~ 类型
的变量转化为 ~array~ 类型然后再进行绘制：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图中我们显示了以承重能力作为纵轴，特征值作为横轴，绘制其每个样
本 $8$ 个特征值的散点图矩阵：

#+BEGIN_QUOTE
图9.4：以承重能力作为纵轴，特征值作为横轴，绘制其每个样本 $8$ 个
特征值的散点图矩阵
#+END_QUOTE

通过图9.4我们可以看出，目前这个阶段还很难从散点图中获得有用的信息，
所以我们被迫先使用一些简单的机器学习方法对数据进行处理。虽然目前
我们无法从中获得明显的模式，但是这正启发我们应该使用一种最适用于
处理高度非线性的模型：'anns_snp'对数据集进行拟合。

正如第七章，人工神经网络——模拟人脑思考方式，中所讲述的，数据拟合
就是找到一个能以最高精度实现从输入数据到输出数据的映射的数学函数。
数据拟合具有诸多应用场景，例如数据处理中应对缺失值的插值法、处理
奇异值的平滑方法，以及回归分析等。在这里我们数据拟合的目的是建立
一个最小化拟合误差、最大程度克服样本中的随机噪声，实现从输入数据
到输出数据映射的回归方程。从数据集中拟合出的方程能够帮助我们可视
化数据、预测混凝土承重能力、发现不同配方原料与承重能力的潜在关系。

本章与第七章，人工神经网络——模拟人脑思考方式，不同，鉴于我们已经
系统学习过'nntb_snp'，这里我们将脱离GUI，直接使用工具箱函数编写程
序脚本调用神经网络。首先我们来对数据集进行定义。之前我们已经将原
始数据集导入到工作空间中，并将特征矩阵（前 $8$ 列，混凝土配方使用
的 $8$ 种原料）与目标值（混凝土强度）分离出来，将其保存在两个矩阵
中（分别是 ~X~ 和 ~Y~ 矩阵）。但是这里我们需要重复强调下在第七章，
人工神经网络——模拟人脑思考方式，中强调过的内容，我们原始数据集保
存数据的方式是每行代表一个样本，每列代表一个特征值。但是'nntb_snp'中
的函数反过来，默认输入数据每列代表一个样本，每行代表一个特征值。
下面的代码仅仅因为这个工具箱的特殊原因对矩阵进行转置，不存在其它
模型建立上的特殊意义：

#+BEGIN_QUOTE
代码
#+END_QUOTE

现在 ~X~ 仍然表示特征矩阵， ~Y~ 仍然表示目标向量。我们接下来必须
确定神经网络的训练算法。这里回顾下，我们可以通过设置
~net.trainFcn~ 属性更改神经网络的默认训练算法，MATLAB提供给了我们
三种常用算法：

- *Levenberg-Marquardt* (~trainlm~) ：适用于绝大多数神经网络
- *Bayesian Regularization* (~trainbr~)：对于小数据集、噪声较多的
  数据集适用，但训练时间更长
- *Scaled Conjugate Gradient* (~trainscg~)：适用于大数据集。这个
  算法使用梯度作为神经网络更新权重的依据，而非雅克比矩阵，因此在
  内存使用上更具效率

我们可以使用如下命令获得MATLAB提供的全部训练算法：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里我们使用默认算法 ~Levenberg-Marquardt~ 作为反向传播算法：

#+BEGIN_QUOTE
代码
#+END_QUOTE

一旦我们选定训练算法后，我们可以继续对神经网络结构进行定制。这里
我们主要对神经网络的隐含层所包含的神经元数量进行更改。在这里我们
选择创建一个大小为 $10$ 个神经元的隐含层：

#+BEGIN_QUOTE
代码
#+END_QUOTE

为了构建回归方程，我们需要使用 ~fitnet()~ 函数建立相应的神经网络，
这个神经网络将返回一个用于回归拟合的，隐含层大小为
~hiddenLayerSize~ 的前向传播神经网络：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里我们只是对神经网络的结构进行了定义，我们还没有对神经网络进行
任何输入、输出、训练等运算。在这之前首先我们来看一下我们定义的神
经网络结果，函数 ~view()~ 能够绘制网络结构图：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图中我们注意到输入和输出层的大小都是 $0$ ：

#+BEGIN_QUOTE
图9.5：神经网络结构图
#+END_QUOTE

记得前面的章节中讲过，在正式进行任何机器学习模型运算前，我们首先
对原始数据集进行预处理，来避免缺失值、奇异值等等问题对模型产生的
不良影响。这里我们对数据集进行去量纲化，即标准化、正则化处理，
'nntb_snp'提供了以下函数完成此项任务：


- ~fixunknowns~ ：保留数据集中的缺失值
- ~mapminmax~ ：将特征值矩阵标准化到 $[-1,1]$ 的区间
- ~mapstd~ ：将特征值标准化到正态分布
- ~processpca~ ：使用'pca_snp'进行数据预处理
- ~removeconstantrows~ ：删除包含常量的行
- ~removerows~ ：删除制定行数的行

例如，我们可以删除任何输入、输出矩阵中是常数的行。因为是常数的特
征值对任何机器学习算法而言都不具备学习意义，并且可能会因为某些数
值计算方法造成问题（除数为 $0$ 等）：

#+BEGIN_QUOTE
代码
#+END_QUOTE

在创建神经网络、并对神经网络制定了数据预处理方案后，我们现在需要
对数据集进行划分了。还记得数据集是如何划分、每个子数据集所承担的
作用吗？一般而言，拟合算法，甚至可以说大部分机器学习算法，都通
过有限的数据集对问题进行拟合、从中学习潜在的模式。在训练阶段，模
型的精度是通过计算模型的输出结果与真实值的误差得到的。然而任何机
器学习模型的最终应用，都是通过输入模型在训练阶段没有见到过的样本
的特征向量，对目标值做出预测。模型在这个过程中的表现即体现了模型
的泛化能力，也就是模型通过学习历史数据，对未知数据进行预测的能力。
过拟合问题指的是模型在训练集上具有极高的拟合精度，但在测试集，也
就是新样本的预测上表现极差的现象。

为了避免模型在训练阶段出现过拟合问题，研究者设计了一套分阶段、分
数据集的训练方法，用于能在出现过拟合现象时及时识别，甚至在出现过
拟合前预先停止训练。这套方法的核心概念在于将整个原始数据集划分为
三个数据集：训练集（Training）、验证集 （Validation）、测试集
（Testing）。这里我们对三个数据集的划分方法及其作用进行简要回顾：

- 训练集（Training）：训练集中的样本用于求解模型参数。对神经网络
  意味着权重参数和偏置项
- 验证集（Validation）：在训练完毕后，验证集的样本将被输入参数，
  模型在验证集上的表现被用于衡量模型对训练集的拟合能力。如果验证
  集表现不足，证明当前模型不具备拟合数据集的能力，需要重新设计模
  型进行训练、验证
- 测试集（Testing）：模型在训练集样本上的表现被视为对模型泛化能力
  的最终测试。通过观察测试集误差，我们能够观察到过拟合、拟合不足
  等问题。测试集表现是评估模型好坏、挑选最终模型的标准

通常在训练过程中，前几个迭代是训练集、验证集上误差下降最快的迭代。
当出现过拟合现象时，往往只有训练集上误差不断下降，而验证集上错误
反而上升。算法返回的参数，是模型在验证集上误差最小时的迭代求解出
的参数。实际中，测试集上的误差与验证集上的误差应当基本上是同步变
化的。然而如果出现，验证集与测试集在相差很大的迭代次数分别达到最
小值，这往往意味着三个数据集的划分有问题，需要重新划分。

MATLAB提供了如下四种划分三个数据集训练集（Training）、验证集
（Validation）、测试集(Testing) 的方法：

- ~dividerand~ ：默认方法，随机划分
- ~divideblock~ ：将样本按照原始数据集中的顺序，连续地分为三块
- ~divideint~ ：运用插入法对数据集进行划分
- ~divideind~ ：按照样本行数进行划分

神经网络对象 ~net~ 有诸多属性，通过改变这些属性我们可以深度定制模
型及其算法等参数。例如，我们可以通过如下属性改变数据集的划分：

#+BEGIN_QUOTE
代码
#+END_QUOTE

除了选择划分算法，我们还可以对每个算法使用的参数进行定制：

#+BEGIN_QUOTE
代码
#+END_QUOTE

最后我们可以定制算法划分目标向量时所使用的方法：

#+BEGIN_QUOTE
代码
#+END_QUOTE

默认的划分方法是 ~'sample'~ ，这是对静态网络进行使用的，将按照样
本数量比例对数据集进行划分（如前向传播神经网络）。对于动态神经网
络，如果数据集中设置有时间戳，我们可以将其设置为 ~'time'~ ，这样
将按照时间戳的粒度进行划分。我们还可以将其设置为 ~'sampletime'~
来同时针对样本个数和时间序列进行划分。设置为 ~'all'~ 将按照数值对
目标向量进行划分，如果设置成 ~'none'~ 则不进行划分（这个选项只对
训练集的划分方法起作用，而不影响验证集和测试集）。

这里我们使用 ~'dividerand'~ 作为划分方法：

#+BEGIN_QUOTE
代码
#+END_QUOTE

并且按照每个子数据集中样本数量占总数据集样本数量的比例进行划分：

#+BEGIN_QUOTE
代码
#+END_QUOTE

划分三个数据集所使用的比例为：

#+BEGIN_QUOTE
代码
#+END_QUOTE

现在我们对衡量神经网络拟合精度的指标进行设置。MATLAB提供了如下指
标以供选择：

- ~'mae'~ ：绝对均值误差
- ~'mse'~ ：均方误差
- ~'sae'~ ：绝对误差和
- ~'sse'~ ：平方误差和
- ~'crossentropy'~ ：交叉熵
- ~'msesparse'~ ：使用2范数作为误差函数，且使用1范数作为正则化项
  以保证稀疏性的均方误差（1范数作为正则项会导致稀疏的求解结果，即
  大部分参数接近 $0$ ，只有小部分参数不为 $0$ ，这样可以增强模型
  可解释性）

这里我们使用均方误差作为衡量指标：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下面我们将对模型训练过程中用到的可视化结果相关参数进行设置。我们
有许多可用于可视化模型训练过程的图表，可以通过如下命令查看这些图
表：

#+BEGIN_QUOTE
代码
#+END_QUOTE

我们选择如下图表对前向传播神经网络的训练过程进行可视化：

#+BEGIN_QUOTE
代码
#+END_QUOTE

进行诸多设置后，我们终于可以使用 ~train()~ 函数训练神经网络了。这
个函数将使用 ~net.trainFcn~ 和 ~net.trainParam~ 中的设置对网络进
行训练：

#+BEGIN_QUOTE
代码
#+END_QUOTE

~train()~ 函数的输入数据有：

- ~net~ ：神经网络对象
- ~X~ ：神经网络输入矩阵
- ~Y~ ：神经网络目标向量

它将返回：

- ~net~ ：训练后的神经网络对象
- ~tr~ ：训练记录（每个 ~epoch~ （训练集中全部样本被学习一次，成
  为一个 ~epoch~ 。整个训练过程需要反复对全部训练集学习多次，直到
  达到停止条件）的表现指标）

在训练神经网络时，将会自动弹出一个可视化窗口，它将显示训练有关的
各种数据。在这个窗口中，总共显示四类数据：神经网络结构、训练算法、
训练过程、根据各种指标绘制的图表。每类数据都对理解训练过程中发生
了什么至关重要。

神经网络结构（Neural Network）区域绘制了我们正在训练的神经网络的结构图。将这幅图与
之前的图9.5进行比较，我们看到当前的神经网络输入层和输出层具有正确
的神经元数量（ $8$ 个输入神经元， $1$ 个输出神经元）。

训练算法（Algorithms）区域显示了训练过程中一些非常重要的参数，例如有数据集的划
分方法（ ~dividerand~ ），选用的训练算法（ ~trainlm~ ），衡量模型
表现的指标（ ~mse~ ）。在训练过程区域（Progress）我们能够看见训练
的实时进展。在最后的绘图（Plots）区域，列出了可绘制的所有图片类型
及其对应的按钮。通过点击这些按钮，我们能够在新弹出的窗口中查看这
些图片。整个 *Neural Network Training* 窗口如下图所示：

#+BEGIN_QUOTE
图9.6： *Neural Network Training* 窗口
#+END_QUOTE

之前我们提到过， ~train()~ 函数将会返回两个变量： ~net~ 和 ~tr~
。第一个是神经网络对象，第二个则记录了整个训练过程中的各种指标。
我们可以通过 ~plotperform()~ 函数查看训练过程中衡量神经网络表现指
标的变化过程。这也是 *Neural Network Training* 窗口绘制图形部分的
第一个按钮：

#+BEGIN_QUOTE
代码
#+END_QUOTE

~plotperform()~ 函数绘制了整个训练过程中，神经网络精度（这里是均
方误差）在各个数据集上的变化过程。 *Neural Network Training* 窗口
中的绘画区域中第二个按钮是 *Training State* 图片（对应函数为
~plottrainstate()~ ），它将对整个训练过程中 ~train()~ 函数产生的
数据进行展示：

#+BEGIN_QUOTE
代码
#+END_QUOTE

如下图所示，两副图片都对我们之前训练神经网络的整个过程提供了非常
重要的信息：

#+BEGIN_QUOTE
图9.7：神经网络训练表现图（左侧）；神经网络训练状态图（右侧）
#+END_QUOTE

至此，神经网络已经训练完毕，可以应用到实际数据集中了。我们训练神
经网络的目的是将其应用于，通过混凝土的制作配方，预测混凝土的承受
能力指标。为了检验模型预测效果，我们首先可以把已有的数据集重新输
入神经网络，使其对已有数据集进行预测，并将预测结果与这些数据集的
真实指标进行比较。通过这种比较，我们能够得出神经网络预测能力的初
步结果：

#+BEGIN_QUOTE
代码
#+END_QUOTE

第一行代码使用了刚刚训练好的神经网络对象 ~net~ ，对整个数据集 ~X~
进行预测，并将输出结果保存成变量 ~Ytest~ 。第二行代码则使用了
~gsubtract()~ 函数，通过计算两个向量，神经网络预测结果 ~Ytest~ 和
真实目标向量 ~Y~ 之间的差值，作为神金网络的预测误差向量 ~e~ 。通
过这种方法，我们得到了神金网络对每个样本的预测误差值。最后一行代
码通过使用 ~perform~ 函数，根据之前定义的衡量指标
~net.performFcn~ （在这里我们使用的是均方误差 ~'mse'~ ）对模型表
现进行衡量。

我们有诸多工具来评估神经网络的性能，前面提到的预测误差指标只是其
中一种。更直观的方法是我们可以绘制神经网络预测误差 ~e~ 向量的箱状
图，来对误差在样本间的分布状况进行可视化：

#+BEGIN_QUOTE
代码
#+END_QUOTE

最后，我们可以使用 ~plotregression()~ 函数来评估神经网络对目标向
量拟合结果的好坏。这个函数将使用线性函数，以神经网络预测结果为输
入向量，对真实目标向量进行线性拟合。下面的代码首先从数据集中按照
划分分别提取了训练集（Training）、验证集 （Validation）、测试集
（Testing）的计算结果，并将其和总数据集一起绘制成了线性回归图：

#+BEGIN_QUOTE
图9.8：预测误差箱状图（左侧）；预测结果对目标向量线性回归图（右侧）
#+END_QUOTE


** 使用神经网络诊断甲状腺疾病

甲状腺是人类非常重要的一个器官。甲状腺能够调节人体的新陈代谢，而
且控制着心率、神经系统、身体成长、肌肉力量、性功能等诸多身体功能。
正因甲状腺如此重要，当这个腺体出现问题时，病人会非常痛苦。

甲状腺功能异常会造成许多症状。例如，甲状腺会加快或减慢身体的某些
代谢过程，分泌过多的或过少的荷尔蒙激素。这些现象被称作甲状腺机能
亢进（甲状腺产生了过激的反应）或者甲状腺机能减退（甲亢的相反，甲
状腺分泌的激素过少）。

本节我们将构建一个能够通过病人的生理数据对其甲状腺功能进行诊断的
分类模型。首先我们需要准备数据集。这次我们直接使用MATLAB自带的数
据集。我们之前在介绍MATLAB运行环境时提到过，许多工具箱都自带了学
习、演示为目的的数据集。我们可以通过制定数据集名称的方式，使用
~load~ 命令将数据集导入工作空间。这里我们将使用 ~thyroid_dataset~
：

#+BEGIN_QUOTE
代码
#+END_QUOTE

现在MATLAB的工作空间中将会载入两个变量：

- ~thyroidInputs~ ：一个大小为 $21\times 7200$ 的矩阵，其中收集了
  $7200$ 个病人的生理指标。包括 $15$ 个二元指标（ $0$ 或 $1$ ）和
  $6$ 个连续值指标
- ~thyroidTargets~ ：大小为 $3\times 7200$ 的矩阵，其中收集了对
  $7200$ 个病人的诊断结果

在 ~thyroidTargets~ 矩阵中，类别标签使用 $1$ 在三行中进行标注。如
果 $1$ 出现在第一行，表示诊断结果是正常。如果 $1$ 出现在第二行，
表示病人被诊断为甲亢 ~hyperfunction~ 。如果 $1$ 出现在第三行，病
人则被诊断为甲减 ~hypothyroidism~ 。

目前的困难在于如何识别甲减病人，因为数据集中只有 $8\%$ 的病人被诊
断为甲亢。因此一个具有优秀性能的分类模型必须能够成功诊断甲减。

现在我们先对输入、输出变量进行定义：

#+BEGIN_QUOTE
代码
#+END_QUOTE

接下来我们必须选择训练算法。我们可以使用 ~net.trainFcn~ 对神经网
络训练算法进行修改。通过以下命令我们能够查看全部可用的算法：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里我们选择共轭梯度下降算法：

#+BEGIN_QUOTE
代码
#+END_QUOTE

在设置好训练算法后，我们可以对创建好的神经网络结构进一步进行定制。
这里我们仅修改隐含层包含神经元的数量。我们将创建一个包含 $10$ 个
神经元、一个隐含层的前向传播神经网络：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里我们的问题变为了分类问题，因此我们需要使用 ~patternnet()~ 函
数创建分类神经网络。分类神经网络同样是前向传播神经网络，但它的输
出层可以有任意多个神经元，用于满足多分类问题（数据集有多个分类标
签）。神经网络的目标向量是对每个样本（之前提到过，在'nntb_snp'的
输入数据中为每列），对应类别标签为 $1$ ，其余元素取值为 $0$ 的矩
阵。这个函数接受以下输入变量：

- ~hiddenSizes~ ：行向量，长度与隐含层数相同，每个元素的数值代表
  对应隐含层包含神经元的数量（默认为 $10$ ）
- ~'trainFcn'~ ：训练算法（默认为 ~'trainscg'~ ）
- ~'performFcn'~ ：衡量指标（默认为 ~'crossentropy'~ ）

函数的返回值是一个神经网络对象：

#+BEGIN_QUOTE
代码
#+END_QUOTE

创建神经网络后，我们需要对训练集（Training）、验证集
（Validation）、测试集（Testing）进行划分：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里我们不再详细介绍每行代码的意义，因为上面一节已经介绍过。这里
与上节完全相同。如果读者在这里有任何疑问，你需要返回上一小节进行
复习。

这里我们选取了'cren_snp'对神经网络计算结果进行衡量。这个指标是分
类和模式识别问题的默认指标，它使用神经网络预测结果和真实值，计算
两者的'cren_snp'：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里我们选择绘制如下图表对训练过程进行可视化：

#+BEGIN_QUOTE
代码
#+END_QUOTE

现在可以对神经网络进行训练了：

#+BEGIN_QUOTE
代码
#+END_QUOTE

在训练神经网络时，将会自动弹出一个可视化窗口，它将显示训练有关的
各种数据。在这个窗口中，总共显示四类数据：神经网络结构、训练算法、
训练过程、根据各种指标绘制的图表。每类数据都对理解训练过程中发生
了什么至关重要，如下图所示：

#+BEGIN_QUOTE
图9.9：模式识别的 *Neural Network Training* 窗口
#+END_QUOTE

为评估训练后神经网络的预测能力，我们可以使用训练后的神经网络对数
据集进行预测，再将预测结果与真实目标矩阵进行比较：

#+BEGIN_QUOTE
代码
#+END_QUOTE

前三行代码与上一小节中的作用完全相同。下面 ~vec2ind()~ 函数起到了
将之前提到的，使用 $1$ 在三行中作为标记，用于表示样本属于哪个类别
标签的目标矩阵 ~TargetData~ ，转化为一个使用数字 $1$ 、 $2$ 、
$3$ 作为标签的向量。前一种矩阵更适用于神经网络拟合，后一种向量更
适用于计算神经网络预测能力指标。最后一行代码则计算了百分制衡量的
分类误差。

接下来我们将提取三个数据集训练集（Training）、验证集
（Validation）、测试集（Testing）的预测结果和真实结果，用于下面分
数据集的模型表现衡量：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下面的代码将对三个数据集，和总数据集的'confmat_snp'绘制图像：

#+BEGIN_QUOTE
代码
#+END_QUOTE

通过'confmat_snp'，我们能够评估神经网络对真实数据集的预测能力。前
面的章节中对混淆矩阵进行了详细介绍，这种矩阵能够显示模型所犯的各
种类型的错误细节。在这个矩阵中，对角线上的矩阵显示的是预测正确的
样本数量，其余的元素是错误分类的样本数量。

在理想情况中，机器学习能够对健康、生病两种状态进行精确预测，即没
有样本会被错分到另一类别中。然而，现实情况是经常有生病的患者被预
测成健康、健康的人被预测成生病。

下图中显示了训练、验证、预测集的混淆矩阵，以及总数据集的混淆矩阵
（注意，之前我们解决的都是二分类问题，这里是三分类问题，因此混淆
矩阵的大小是 $3\times 3$ ，多余的行和列是对应行列的求和）：

#+BEGIN_QUOTE
图9.10：分数据集显示的混淆矩阵，和总混淆矩阵
#+END_QUOTE

图9.10中，右侧、底部蓝色的方块现实的是，左侧、上方绿色方框中，每
部分的加总数值。这里面绝对值显示的是样本数量，百分数是在总数据集
中所占比例。在混淆矩阵中，横坐标表示的是样本的真实值，纵坐标表示
的是神经网络预测的结果。例如在图9.10左上角第一幅图中，第一列告诉
我们，有 $91$个样本被正确分类为第一类（正常）， $15$ 个第一类的样
本被神经网络分类到第二类（甲亢）， $14$ 个被分类到第三类。最右侧
的列，即蓝色列，对预测结果进行总结，上面的数值是每类被正确预测的
样本比例，下面的数值则是被错分的比例。通过观察9.10，我们看到神经
网络在测试集上（左下图）仍然有非常优秀的分类精度（ $93.6\%$ 的正
确分类率 ）。因此我们说这个神经网络已经具备了很好的泛化能力。如果
我们需要更高的精度，我们可以修改之前的参数，重新训练神经网络。

除了混淆矩阵，另一个衡量标准是'roc_snp'。下面的代码对每个数据集及
总数据集绘制了'roc_snp'：

#+BEGIN_QUOTE
图9.11：对三个子数据集和总数据集绘制的'roc_snp'
#+END_QUOTE

MATLAB对不同类别的曲线使用不同颜色进行标注。ROC曲线绘制了TP（true
positive，不熟悉的读者请回顾第五章中讲述混淆矩阵的章节）样本数量
对FP（false positive）样本数量的比率。曲线越向左上角凸，说明对该
类别的分类精度越高。


** 使用模糊聚类对学生进行分簇

有效的教学活动需要教师提前做出精准、科学的教学规划。教学规划是指
以安排一系列逻辑严密的、以提高教学质量和学习效率为目标的教学活动
的规划方法。通过教学规划，教师能够避免出现针对突发情况即兴发挥、
低效率等状况，并能够科学有效、逻辑严密地组织一系列教学活动和考试。
一个精准、科学的教学规划，需要根据不同学生群体的文化、情绪、学习
努力程度和知识水平不同，具体地、有针对性地提出教学措施。下图显示
了同一个教室中的两种学习状态：

#+BEGIN_QUOTE
图9.12：一个教室中的两种学习状态
#+END_QUOTE

为了制定科学有效的教学规划，教师需要针对每个学生、不同的学生群体，
个性化地定制教学方案。而能够执行的前提是我们必须具有足够多能够描
述每个学生特征的数据集。为了这个目标，我们针对不同学生的学术水平
和努力程度计算了相关指标并收集了数据集。这些指标提前经过了标准化
处理。数据集的目标是使教师能够将学生分成各个群体，并对不同群体制
定个性化的教学方案。

现在，我们使用名称为 ~ClusterData.dat~ 的数据集进行举例。我们可以
直接使用 ~load~ 命令将 ~ClusterData.dat~ 数据集加载到MATLAB的工作
空间中。读者需要注意该数据文件必须在MATLAB当前工作文件夹中，否则
将会找不到文件：

#+BEGIN_QUOTE
代码
#+END_QUOTE

我们首先对数据集绘制散点图：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图显示了数据集 ~ClusterData.dat~ 绘制的散点图：

#+BEGIN_QUOTE
图9.13：学生数据集散点图
#+END_QUOTE

图9.13中根据学生的努力程度（motivational skills）和学习能力
（cognitive skills）绘制了散点图。

我们的目标是从学生的样本数据集中识别出潜在的分组，以根据不同类别
的学生定制授课方案。这里我们使用'fltb_snp'对数据集使用'fcm_snp'的
方法对数据集中的样本进行聚类分析。

通过分析图9.13，我们可以看出所有样本点大概可被划分为四个区域，因
此在这里我们首先设置聚类中心个数 $K=4$ 。如果通过散点图我们不能清
楚估计可能的聚类中心个数，我们可以使用模糊递减聚类算法，从较多聚
类中心个数开始尝试，逐步缩减聚类中心个数，试验出最佳结果。这种方
法能够快速估计出数据集中潜在的聚类中心个数。通过这种方法估计出的
聚类中心，可以被用来初始化'fcm_snp'的聚类中心。这里我们使用
~subclust()~ 函数进行模糊递减聚类算法。

模糊递减聚类算法假设每个样本点都是一个聚类中心，为了得到更精确的
聚类结果，算法迭代地执行以下五步：

1. 根据样本点周围的样本点，计算这个样本点是一个聚类中心的概率
2. 使用具有最高概率的样本点作为第一个聚类中心
3. 将第一个聚类中心范围内的所有样本点剔除出数据集，范围使用
   ~clusterInfluenceRange~ 属性定义的指标进行衡量
4. 再剩余样本中，选取概率最高的样本点作为聚类中心
5. 不断重复3、4步，直到所有样本点都有所属的聚类中心

~subclust()~ 函数接受两个变量，需要聚类的数据集，以及每次剔除范围
的阈值，并返回聚类中心作为计算结果。模糊递减算法能够自动估计出输
入数据集中潜在的聚类中心数量。剔除范围的阈值是一个 $[0,1]$ 范围内
的数值。阈值选择的小，则会产生较多的聚类中心，且每个聚类中心较小。
这里我们设为 $0.6$ ：

#+BEGIN_QUOTE
代码
#+END_QUOTE

现在我们通过查看聚类中心矩阵的大小，来显示自动估计的聚类中心数量：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这里返回了一个大小为 $4\times 2$ 的矩阵，其中 $2$ 是使用两个特征
值作为聚类中心的坐标。矩阵有 $4$ 行代表算法找到了 $4$ 个聚类中心。
现在我们将聚类中心标注在之前绘制的散点图中：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图中显示了原始数据集中的样本点，并标注了模糊递减算法确认的聚类
中心：

#+BEGIN_QUOTE
图9.14：标注有聚类中心的散点图
#+END_QUOTE

现在我们得到了模糊递减聚类算法自动估计的聚类中心数量，这与我们最
初从观察图形得到的数量 $4$ 是一致的。现在我们可以正式使用'fcm_snp'进
行聚类分析了。这个算法是由Jim Bezdek在1981年发明的，它能够计算每
个样本属于各个计算中心的归属度。Bezdek发明这个算法的目的是对当时
最先进的聚类算法进一步改进。'fcm_snp'是一个能够将每个样本归属到不
同聚类中心的聚类算法。

在MATLAB中，'fcm_snp'算法可以使用 ~fcm()~ 函数进行计算。这个算法
会根据用户指定的聚类中心数量，随机初始化相应数量的聚类中心，同时
计算每个样本对各个初始化聚类中心的归属度是多少。初始化的聚类中心
的位置可能是完全错误的。与'kmean_snp'算法类似，FCM算法同样采取迭
代的方式，逐步对聚类中心的位置进行优化。其每次迭代的优化目标是最
小化每个样本到其所属的聚类中心的距离，其中函数所使用的目标函数和
距离的衡量指标都是可以由用户进行定制的。 ~fcm()~ 函数最终返回聚类
中心的坐标，以及每个样本对各个聚类中心的归属度。

从之前的分析中我们已经知道，数据集中可能存在 $4$ 个聚类中心。接下
来我们通过 ~fcm()~ 算法来计算这些聚类中心的具体坐标，这个算法将在
目标函数不再下降时停止：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这个函数将会返回三个变量：

- ~centers~ ：算法收敛后聚类中心的坐标，其中每行代表一个聚类中心，
  每列是对应原数据集中特征值的聚类中心坐标
- ~U~ ：模糊分块矩阵，其行数与聚类中心数量相同，列数与特征值数量
  相同。其中 ~U(i,j)~ 表示的是数据集中第 $j$ 个样本点对第 $i$ 个
  聚类中心的归属度。对于每个样本点，它对所有聚类中心的归属度的和
  为 $1$
- ~objFunc~ ：每次迭代的目标函数值

我们之前说过，FCM算法通过多次迭代逐渐优化聚类结果。我们可以通过绘
制目标函数变化过程进一步查看算法是如何聚类的：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图显示了目标函数的变化过程：

#+BEGIN_QUOTE
图9.15：目标函数值
#+END_QUOTE

通过图9.15我们可以看出，在这幅图前几个迭代时目标函数值下降速度非
常快，这说明算法聚类结果朝着目标快速优化，当目标函数曲线逐渐平稳
时，意味着算法开始逐渐收敛。现在我们将绘制使用 ~fcm()~ 函数聚类后
的所有样本点使用四个聚类进行标注的散点图。图中我们使用一些特殊记
号对聚类中心进行标注。

第一步首先我们要获得每个样本所属的聚类中心ID。我们已经提到过，变
量 ~U~ 保存的是 ~fcm()~ 函数衡量的，每个样本到各个聚类中心的归属
程度。对于每个聚类中心，样本点的归属度是 $[0,1]$ 范围内的数值。我
们选取拥有最大的数值的聚类中心作为该样本点所属聚类中心。首先我们
获得每个样本最大的归属度的数值，并将其保存在向量 ~maxU~ 中：

#+BEGIN_QUOTE
代码
#+END_QUOTE

接下来我们就可以计算出每个样本所属的聚类中心ID。我们可以通过查找
每个样本的第几列数值与其最大值相等，并输出该列的列号来实现此点。
这里我们可以使用 ~find()~ 函数来获取非 $0$ 元素的行号：

#+BEGIN_QUOTE
代码
#+END_QUOTE

现在我们已经获得了绘制散点图所需要的所有信息，我们可以开始绘制散
点图了。首先，我们对样本点进行绘制（样本点的坐标就是每个学生学习
努力程度和知识水平的得分，即特征值）。这些点将根据其所属的聚类中
心被渲染成不同的颜色，并用不同的形状予以显示：

#+BEGIN_QUOTE
代码
#+END_QUOTE

接下来我们将 ~fcm()~ 函数计算的聚类中心在散点图中标注出来，这些聚
类中心将使用不同的颜色和特殊标记予以区分：

#+BEGIN_QUOTE
代码
#+END_QUOTE

最后我们对散点图添加标题和横纵坐标注释：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图显示了样本点聚类结果即聚类中心：

#+BEGIN_QUOTE
图9.16：根据学生努力程度（motivation skills）和学习能力
（cognitive skills）使用 'fcm_snp' 进行聚类的结果
#+END_QUOTE

从图9.16中我们能够看出，聚类算法给出的三个聚类的划分方式在视觉效
果上非常明显。'fcm_snp'返回的聚类中心与使用模糊递减聚类算法得到的
聚类中心非常相近。现在我们对每个学生所属的聚类都进行了标注，并且
可以根据不同类别的学生实施个性化的教学方案了。显然，学习不努力的
学生与学习能力有缺陷的学生是需要使用完全不同的教学方法对待的。

与之前的聚类算法相同，FCM返回的聚类结果在聚类的边界处仍然显示出一
些混乱。对于这些所属类别不明显的学生，教师可能需要花费更多力气，
不断尝试以制定出最符合其特点的教学方案。


** 总结

作为本书的结尾，本章综合了之前章节介绍的各种模型，并且将这些模型
应用到了实际数据集中解决实际问题。本章很简略地对这些模型进行了回
顾，重点放在应用机器学习解决问题的流程，以及分析、解决问题的方
法、思路上。

本章首先解决了一个回归问题。我们建立了一个能够通过分析混凝土配方，
对混凝土承重能力进行预测的神经网络模型。这部分我们使用了MATLAB提
供的数据导入工具对原始数据进行预处理，并使用'nntb_snp'对回归问题
进行数学建模。

接着我们使用神经网络解决了一个多分类问题。这里我们建立了能够通过
生化指标判断患者甲状腺是否异常的分类器。这部分我们使用了MATLAB自
带的数据集。同时我们学习了如何理解多分类的'confmat_snp'和'roc_snp'。

最后我们进行了聚类分析。这里我们的目标是根据不同学生努力程度和学
习能力的不同，将学生聚类成几组，并对不同组的学生制定个性化的教学
方案。这里我们使用了两种模糊聚类算法：模糊递减聚类和'fcm_snp'。这
两个算法都已经封装在'fltb_snp'中，可以很方便地直接调用。
