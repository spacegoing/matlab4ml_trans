#+LATEX_HEADER: \usepackage{ctex}
#+LATEX_COMPILER: xelatex



* 第七章：人工神经网络——模拟人脑思考方式

'anns_snp'是由一系列层次化的、对变量线性组合进行非线性变换的函数
构建的数学模型。它使用极其简单的数学理论，但通过大量运算、层次化
结构，能够对任意复杂的数学模型进行精度非常高的逼近。通过神经网络
我们能够模拟诸多复杂的人脑活动，例如图像识别、模式识别、语言理解、
空间感知等。神经网络的结构是对人脑神经元结构的一种简单模仿，网络
中的节点相当于人脑中的神经元，链接节点的权重相当于神经元间突触的
链接强度。神经网络往往由输入层、多个隐含层以及输出层构成，浅层神
经网络的输出作为深层神经网络的输入，每层隐含层网络都对输入进行非
线性变换。输入层中，每个节点都对应着样本特征向量中的一个特征值，
输出层中的节点则代表模型计算结果。

MATLAB提供了'nntb_snp'用于训练、调用模型，并且针对工具箱制作了非
常精美的可视化APP用于构建、训练、可视化以及仿真神经网络。我们可以
使用它来进行分类、回归、聚类、降维、时间序列预测以及动态系统建模
与控制。工具箱中封装了专门的数据结构和算法用于模型构建、训练和使
用。通过这些函数，我们能够对任意数据集进行拟合并从中学习隐含的模
式。

本章将讲述如何使用神经网络拟合数据、分类及聚类。你讲学习如何进行
数据预处理、构建和训练网络、结果处理、可视化神经网络以及模型评估。
我们还将学习在调用神经网络前如何对数据集预先进行划分。

我们将涵盖以下主题：

- 创建、训练和仿真神经网络
- 拟合数据
- 使用工具箱的GUI
- 使用工具箱中的函数

在本章结尾，我们将理解神经网络的基本概念以及如何在MATLAB环境中实
现神经网络模型。我们将学会如何准备数据集、如何进行数据拟合以及如
何使用工具箱中的函数理解模型、参数等各种细节。


** 神经网络简介

现代计算机能够非常快速、精确、稳定地计算一系列被预先设计好的运算，
对重复性计算问题具有非常强大的处理能力。这些硬件设备非常强大，但
是并不智能。在整个过程中，唯一智能的环节是程序员编写程序时，对问
题做出的分析和判断并转化成程序命令的过程。对于一个系统，如果想被
称为智能系统，至少得能够解决一些人类觉得简单、直观的问题。

#+BEGIN_QUOTE
图7.1：神经网络大脑漫画
#+END_QUOTE

'anns_snp'通过使用大量的节点、连接权重、网络层次结构，来试图使用
数学和计算机技术模拟生物大脑的神经细胞、神经元和突触。在生物大脑
中，每个神经元平均都链接了数十万个其它神经元，并且拥有不可计数的
突触数量。而生物具有智能的秘诀就隐藏在这些神经元及其链接之中。

这些神经元有的负责接收外部环境的信息，有的对外部环境做出反馈，其
余的神经元负责在理这些信息。这种结构在人工神经网络中被分为三层：
输入层（input）神经元、输出层（output）神经元和隐含层（hidden）神
经元。

#+BEGIN_QUOTE
图7.2：人工神经网络结构图
#+END_QUOTE

其中，每个神经元都进行非常简单的计算：如果接收到的数值超出一定的
阈值，就转为激活状态，并输出某个数值到下一层的神经元。如果一个神
经元被激活，它将对下一层与其连接的所有神经元发送一个相同的数值。
在这种机制中，每个神经元都可以被看成一个缩放器，它通过对接收到的
数值进行判断，放大或者缩小收到的数值，并转发给其它神经元。整个神
经网络中的所有阈值（参数）都不需要预先设定，我们可以使用各种算法
通过拟合数据集自动求解参数，包括监督学习算法、非监督学习算法以及
强化学习算法。

与串行模型按照先后顺序依次处理每个样本不同。每一层的神经元都是相
互独立，因此是并行的。这意味着神经网络可以被用来处理非常大的数据
量。正因为这种并行结构，我们的大脑才得以在瞬间处理极大量的数据信
息，例如我们通过视觉识别某个物体。完成物体识别这种难度级别的任务，
从统计学角度看来需要模型系统有极为优秀的处理噪声的能力（例如识别
房间中的一个杯子，对数学模型而言，桌子、笔等周围的物体都是噪声）。
一旦模型的某个部分受到噪声影响产生错误结果，整个系统都会产生错误。
下图中对比了串行计算（serial processing）和并行计算（parallel
processing）的示意图：

#+BEGIN_QUOTE
图7.3：串行计算、并行计算对比图
#+END_QUOTE

尽管神经网络的结构、运算都很简单，但理解最新的神经网络模型、算法
需要深厚的统计学功底。神经网络强大的拟合能力，极大的规模就同时意
味着即使在诸多假设简化的应用情境中，普通的开发者仍然很难直观地对
模型结果进行预测。然而从工业化、产品化角度，神经网络仍然非常具有
商业价值。即使人脑很难理解，但是不可否认一旦具备了大量的历史数据，
神经网络就能够从中提取出潜藏的模式，并且具有非常好的拟合结果。

因此，尽管神经网络能够从数据集中提取出有效的模式识别方法，但是人
脑很难理解神经网络是如何得到结果的，开发者必须也只能直接接受这些
结果。出于这种状况，人们将神经网络这类模型称为黑盒模型，因为人们
只能理解模型的输入和输出，而不能理解中间的运算过程：

#+BEGIN_QUOTE
图7.4：神经网络——黑盒模型
#+END_QUOTE

与其他模型相同，只有当有良好的训练数据集时，神经网络才能够得到好
的结果。上文提到，神经网络的参数是通过拟合数据集、训练得到的，这
意味着当数据集中有大量样本、样本具有大量特征值时，神经网络会消耗
大量的时间用于训练参数。此外，目前没有理论指导何种结构的神经网络
适用于何种数据集，因此开发者的经验对能否得到好的结果至关重要。

神经网络常用于诸如数据集非常大、没有现成的数学理论能够描述某一具
体问题等情景。这些情景包括光学目标识别、人脸识别、高噪声数据集中
的模式识别等情景。神经网络也是数据挖掘领域的常用工具。近些年中在
计算生物领域神经网络也常被用于发现基因、蛋白质中的模式。


** 神经网络基础构成

'anns_snp'的基本计算单位是神经节点，也就是神经元。人工神经网络中
的神经元是对生物学中神经元一种简化的模仿，它通过前面一层的链接接
受输入数据，将接收到的数据按链接的权重加权求和，再对其计算某种非
线性变换后进行输出。这种模仿建立在生物学对生物神经元的粗浅认知上。
对生物的大脑而言，神经元就是大脑的基本构成单位。而对人脑研究者已
经发现超过100种的神经元结构。下图是对神经元构成的一个极为简化的描
述：

#+BEGIN_QUOTE
图7.5：简化神经元结构
#+END_QUOTE

在生物神经元中，其最重要的功能就是在神经元构成的网络中传递电信号。
这些神经元通过数以万计的输入神经接受并累计电信号，当累积的信号量
超过一定阈值后，就会释放电信号到与之链接的其它神经元。在这个过程
中，作为神经元接受输入链接的神经纤维被称为树突（dentrite），它们
和其它神经元的轴突（axon）相链接，并接受从轴突传播来的电信号给当
前神经元。轴突和树突间的连接点被称为突触（synapse）。下图中显示了
生物学中神经元的基本结构：

#+BEGIN_QUOTE
图7.6：生物学神经元结构图
#+END_QUOTE

整个过程中，突触起到了对传递的电信号进行非线性变换的作用。实际上，
一个神经元可以被类似的看成一个开关，平时状态下神经元处于关闭状态，
当电信号不断累积并超过某一阈值后，神经元将被激活并释放电信号。

目前生物学对电信号传播机制的理解是，电信号从神经元轴突的末端经过
突触传导到下一个神经元的树突。电信号在树突和轴突上的强度并不重要，
重要的是在从轴突到树突传导的连接点突触上。下一个神经元接收到的信
号强度，取决于它与上一个神经元的连接点，即突触的种类。生物学研究
显示，对两组（四个神经元）由不同种类突触链接的神经元，即使两组中
上层神经元通过轴突发出的电信号强度完全相同，经过突触的改变后，两
组中下层神经元树突接受到的电信号完全不同。换个角度而言，突触会对
传递的电信号进行强度的改变。当电信号经过突触传递到树突后，简化地
说，神经元会对其所有树突接收到的电信号进行加权求和，如果电信号累
计超过某一阈值，则会输出电信号。

与生物学的神经元相同，'anns_snp'的神经元同样会接受多个来自上层神
经元的输入。它将所有输入按照连接上的权重加权求和，并进行某种非线
性变换后，与某一阈值进行比较，如果超过阈值则进行输出。

#+BEGIN_QUOTE
图7.7：人工神经元结构图
#+END_QUOTE

神经元所进行的第一个运算是加权求和，这个运算允许神经元接受全部来
自上层神经元的信息。为了区别上层网络中不同神经元输出的信息的重要
性，我们需要对接受的每个信息按照其重要性赋予权重。在这种机制下，
每个上层神经元都或多或少地对这个神经元是否处于激活状态贡献了数值。
这种机制同样存在于生物神经元中。至此，我们描述的神经元的运算是非
常简单的，接下来的主要问题在于如何模仿生物学中神经元的连接节点——
突触上。

之前在描述生物学中的神经元传递机制时已经提到过，突触会对传到中的
电信号进行数值上的改变。经过改变后，即使发时出的信号强度相同，不
同的上层神经元对接受信号的神经元的影响也会变得不同。有些情况下，
经过突触改变的信号对神经元甚至起到抑制作用，它们会使接受信号的神
经元更难被激活。

人工神经元通过两步运算模仿生物学中的这种机制。第一步是上文提到的，
对来自不同上层神经元的输入信号进行加权。权重是一个与输入值相乘的
数值。通过这种加权运算，来源于不同上层神经元的信号对接受神经元会
有不同程度的影响。

#+BEGIN_QUOTE
图7.8：加权后的人工神经元示意图
#+END_QUOTE

如上所述，加权后的神经元会被相加求和：

$$Output=input1*w1+input2*w2+input3*w3+input4*w4+input5*w5$$

其中每个 $input$ 都是一个数值而非向量。现在我们对输入数据及其参数
采用矩阵化表示：

$$INPUT=(input1, input2, input3, input4, input5)$$

$$W=(w1, w2, w3, w4, w5)$$

那么我们就可以将上面求和的步骤写成两个向量的内积：

$$Output=INPUT \cdot W$$

到这里不熟悉线性代数的读者需要找到相关书籍复习一下向量、矩阵以及
矩阵乘法的概念。此处的公式与上个公式并没有任何区别，只不过是用矩
阵的形式表示的两个向量中对应的元素相乘，再将所有乘积相加，结果仍
然是一个数值，即加权总和，而非矩阵。

两个向量的内积一般可看做衡量两向量相似程度的一种粗略的指标。保持
两个向量的长度不变，如果两个向量方向相同，那么内积最大；如果两个
向量垂直，那么内积为0；如果方向相反，则内积最小（且为负数）。从代
数角度而言，两个向量内积就是向量中对应元素的加权求和。

现在我们已经了解了如何用向量的方式表达加权求和，接下来我们来继续
介绍人工神经元模拟生物神经元两个步骤中的第二步：非线性变换。之前
已经说到，生物神经网络的电信号传递过程中，最重要的一步就是突触对
接受、输出值的改变。这种改变并非简单地加权求和，而是非线性的变换。

前文中还提到过，生物神经元只有当电信号达到一定阈值后才会释放，这
也是非线性变换的一种（如现在非常流行的ReLU函数）。那么如何用数学
模型、编程语言来模拟这种非线性变换呢？人工神经网络采取了非常简单
的办法——定义'actfun_snp'（或者变换函数，transfer function，两种命
名完全等价。前种命名在学术界通用，但MATLAB文档中经常出现后者）。
激活函数选取任意一种非线性函数，对加权求和后的数值进行非线性映射
（从输入一个数值到输出一个数值，但这种对应关系是非线性的），并使
用映射后的数值作为神经元的输出结果。

#+BEGIN_QUOTE
图7.9：添加激活函数的人工神经元示意图
#+END_QUOTE

目前学者实践中使用过多种激活函数，这里列举常用的几种：

- A：线性方程
- B：分段方程
- C：Sigmoid函数
- D：双曲正切函数

下图中绘制了四种函数的图像：

#+BEGIN_QUOTE
图7.10：四种激活函数图像
#+END_QUOTE

至此我们已经介绍完人工神经元是如何模拟生物神经元的两步机制。接下
来我们将描述人工神经网络的分层结构。我们将先介绍多个神经元及其连
接是如何构成一层神经网络的，再介绍多层神经网络间如何相互连接。

图7.11显示了下面文字描述的结构：假设我们有两组神经元，每组神经元
都有多个。其中一组神经元负责发送数据，另一组神经元接受之前的数据，
并在进行上文中描述的多步处理后负责产生输出。假设每一个负责接受数
据的神经元，与全部负责发送数据的神经元都存在链接，现在通过给链接
赋予权重值，我们就可以通过调整权重来对不同的模式进行定义（虽然负
责发送数据的全部神经元对每个接受数据的神经元都发送了相同数据，但
因为链接权重不同，不同接受数据的神经元产生不同输出结果）。因此，
每个权重都定义了，当前接受数据的神经元，主要受到哪个发送数据神经
元的影响。这里我们将这一组发送数据的神经元，称为神经网络中的一层
（layer）。

#+BEGIN_QUOTE
图7.11：神经网络中某一层的结构图
#+END_QUOTE

一个神经网络往往是由多层构成的。每加一层神经网络，都扩展了神经网
络逼近更加复杂函数的能力，但同时也增加了神经网络的计算复杂度。其
中，神经网络的第一层，也就是输入层，由于没有来自前面的链接，因此
每个神经元直接接受输入样本的特征值，并将其直接输入给下一层，即第
一层隐含层。我们将夹在输入层和输出层中间的层称为隐含层。从隐含层
开始，每一层中的每个神经元都会进行上文中描述的运算，并将运算结果
继续向下一层传递。大体而言，当我们在讨论神经网络的网络结构时，我
们一般是指神经网络有多少隐含层，每层有多少个神经元，以及最重要的，
这些层、神经元间是如何链接的。例如图7.11中的链接方法，是最基本的
一种神经网络——前向传播神经网络。它之所以被称为前向传播，是因为每
一层中每个神经元的输出值，都会向前传递给与之相连的下一层的神经元，
一直传播到输出层。

通过改变神经元间链接的方式，就能够改变整个神经网络的结构。这不仅
仅是概念、定义角度的改变，链接方式的改变事实上改变了整个神经网络
参数的求解方式，也就直接改变了神经网络逼近其它函数的能力。下图显
示了一个由两层隐含层的深度前向传播神经网络：

#+BEGIN_QUOTE
图7.12：具有两层隐含层的深度前向传播神经网络
#+END_QUOTE

读者可能注意到用词的变化，之前我们一直称'anns_snp'为神经网络，这
里我们将其称为深度神经网络。事实上，学术界对深度神经网络并没有严
格的定义，一般而言隐含层多于一层的任意神经网络，都可以被统称为深
度神经网络。所以这个名称单纯只是命名上的变化，之前所描述的所有神
经网络的机制、原理仍然适用。在图7.12中，我们构建了一个由一层输入
层、两层隐含层、一层输出层的深度前向传播神经网络。其中，输入层和
两个隐含层，每层都具有5个神经元；输出层则只有一个神经元。一般而言，
层数越多、每层神经元越多的神经网络，能越精确地逼近更加复杂的函数。
但是这并不总是成立的，除了神经网络的深度和神经元个数，神经元、不
同层之间的链接方式更为重要，它直接影响神经网络求解参数的算法，我
们能否训练出精度优良、鲁棒性高的模型很大程度取决于此。


*** 隐藏层数量

图7.12中，我们注意到，输入层（5个神经元，对应样本特征向量的长度为
5，即每个样本有5个特征值）和输出层（1个神经元，即一个数值结果）是
由问题、数据集、任务本身决定的，我们并不能人为地进行任何更改。我
们只有在隐含层上才能够自由更改层数、神经元数量、链接方式。隐含层
的层数即神经网络的深度，隐含层的层数和每层包含的神经元数量决定了
神经网络的大小。目前没有理论指导何种结构的神经网络能够适应何种问
题，即无法针对具体问题对神经网络的结构、链接方式从理论层面进行优
化，神经网络的设计完全是凭借主观经验的。一个简单选择最优结构的方
法是，我们可以从简单到复杂，针对同一数据集训练多个结构的神经网络，
然后根据它们在验证集上的实际表现，选择最优的结构作为最终胜出者。


*** 每层中的节点数量

上面我们已经提到过，输入层和输出层的节点数量是由研究的问题决定的。
输入层的节点个数与样本的特征向量长度相同，每个神经元接受一个特征
值作为输入数值；输出层的节点个数取决于研究目标所需的个数，例如对
于分类问题，取决于分类标签的数量，有多少个类别就有多少对应的神经
元。

因此，神经网络的隐含层才是我们研究的重点。上文提到，目前没有理论
来指导隐含层的设计方法。合适的网络结构取决于输入层大小、训练集大
小、研究问题的复杂程度、输出层的大小和其它诸多因素。大型的深度神
经网络能够极好地拟合训练集，但是往往具有过拟合的风险；过小的神经
网络则很容易拟合不足，以致精度下降。另外，大型的神经网络具有很高
的计算复杂度，需要很长时间训练。总之，神经网络的结构设计目前仍然
依赖于经验。


*** 神经网络训练方法

至此我们已经看到，神经网络是由大量极其简单的数学运算集合而成的，
而且这些运算可以并行处理。其中神经元间的链接是研究重点，因为这些
链接代表神经元间的权重，其最能决定网络结构。这些权重无需预先设置，
而是在训练阶段进行求解的。

在训练阶段，神经网络采取先前向传播计算结果、再反向传导误差（通过
比较输出神经元与目标值得到）梯度的形式更新网络中的链接权重，通过
调整链接权重来影响前向传播的计算结果。整个过程不断重复，直至参数
收敛（或满足一定停止条件）。为得到足够鲁棒性的结果，往往需要大量
的样本对神经网络进行训练。

#+BEGIN_QUOTE
图7.13：训练阶段流程图
#+END_QUOTE

具体每次迭代参数是如何更新的，取决于我们使用的训练算法。目前读者
只需要粗略理解训练的流程，我们将在后面实战部分再具体讲述训练算法。


** 神经网络工具箱

MATLAB中的'nntb_snp'已经封装好了诸多算法、预训练模型及其可视化APP
来供用户训练、可视化和仿真神经网络。这些工具不只能够处理浅层神经
网络（只有一层隐含层），对深度神经网络（多于一个隐含层）同样有效。
通过这些工具，我们能够很简单的完成分类、回归、聚类、降维、时间序
列预测以及动态系统建模与控制等任务。

'nntb_snp'有多种方法可以调用，下面列举最常用的四种用法：

- GUI直接调用。我们可以通过在命令行窗口中执行 ~nnstart~ 命令打开
  工具箱的用户界面。通过这个界面我们能够可视化地完成以下任务：函
  数拟合（ ~nftool~ ）、模式识别（ ~nprtool~ ）、聚类分析
  （ ~nctool~ ）和时间序列分析（ ~ntstool~ ）
- 代码直接调用。GUI界面本质就是通过图形化的方式调用工具箱中封装好
  的函数，其好处是非常简便、易于学习，但是实践中问题的复杂度往往
  高于GUI界面的封装程度，通过直接使用工具箱中的函数能够带给我们更
  大的自由度，适应更加困难的问题
- 用户定制神经网络结构。通过GUI界面，我们甚至可以直接定制自己需要
  的网络结构，例如隐含层数、每层神经元的数量，甚至神经元的链接方
  式。工具箱的算法与定制网络结构的GUI无缝衔接，我们可以对自己定义
  的任意结构的神经网络进行训练
- 更改工具箱源代码。对于极度复杂的问题，即使工具箱中函数的封装也
  不足以处理。幸运的是绝大多数函数都是用MATLAB代码编写的，用户可
  以直接更改源代码。工具箱中函数的源代码本身就是我们学习神经网络、
  在MATLAB中实现神经网络的绝佳资源。通过修改源代码能让我们更好地
  学习神经网络，并且能够最大程度适应复杂问题

我们可以看到，MATLAB给各种层次的用户，从初学者到专家，都提供了非
常便利的各种工具简化我们的工作量。实际不止初学者，即使是神经网络
专家，在熟悉使用MATLAB实现的过程中，也可以通过GUI先可视化操作，学
习每一步操作生成的MATLAB代码，然后再结合函数文档编写程序。这种学
习方式非常简单直观，能够极大提高学习效率。

无论我们选择哪种方法使用MATLAB工具箱，在使用神经网络进行建模前我
们都应考虑以下问题：

1. 数据收集
2. 构建神经网络
3. 设置神经网络相关参数
4. 初始化权重参数、偏置项
5. 训练（Train）神经网络
6. 验证（Validate）神经网络
7. 测试（Test）神经网络

#+BEGIN_QUOTE
图7.14：神经网络建模流程图
#+END_QUOTE

建模的第一步是收集我们想要处理的数据，这步通常在使用MATLAB前就已
经执行完毕了。然而，收集到的数据的质量直接决定了模型结果的好坏。
如果数据集本身存在样本匮乏、偏误，数据受到噪声污染等问题，再强大
的模型架构也无法得出优秀的结果。

第二步是建立神经网络。这里工具箱提供了许多便利的函数、算法供我们
调用。这个步骤中我们将会创建一个神经网络对象，这个对象用于保存我
们定义的神经网络相关的全部信息。它有许多非常重要的属性值，例如：

- ~General~ ：关于此神经网络的一些宏观参数
- ~Architecture~ ：此神经网络的架构参数的数量（输入变量、层数、
  权重数据、输出变量、目标变量等）以及不同层间是如何链接的
- ~Subobject structures~ ： ~cell~ 类型变量。保存输入变量、每层结
  构、权重数据、输出变量、目标变量等
- ~Functions~ ：保存用于初始化、训练、评估神经网络所用的算法、函
  数信息
- ~Weight and bias values~ ：保存神经网络算法所训练的参数（算法优
  化的参数结果），例如神经网络的权重

第三步涉及配置神经网络各项参数，例如输入、目标变量所使用的数据，
输入、输出变量的维度，数据预处理算法等参数。一般这步是在训练阶段
由工具箱自动完成的，但是如果用户需要修改默认值以适应更复杂的问题，
需要提前人为修改。

第四步涉及初始化参数权重和每一层的偏置项数值，这些将是算法在第一
次迭代时使用的数值。一般而言这些参数值是工具箱自动初始化的，但是
用户仍可以手动进行更改。

第五步是训练神经网络，这个过程中算法会迭代地修改权重值和偏置项值
以渐进地优化神经网络表现。这是几个阶段中最重要的阶段，训练算法的
好坏不仅影响模型对训练集的拟合精度，同时影响模型在应用到未知数据
集时（测试集或生产环境）的泛化能力。在这一步数据集中的样本将会以
随机顺序被输入模型中进行训练（通常训练集占总数据集的 $70\%$ ）。

第六步是验证(validation)神经网络。工具箱会选取数据集中约剩余样本
的一半（约整个数据集的 $15\%$ ）作为验证集输入神经网络，用于验证
（validate）训练过程中模型的表现。验证的结果用于判断当前神经网络
对训练集拟合程度的高低，如果在这步拟合结果低于预期，那么需要回到
第二步重新设计、建立神经网络进行训练。

最终步骤是测试（test）神经网络。这一步中数据集最后的 $15\%$ 样本
会被输入神经网络，其结果作为对神金网络最终泛化能力的评估。

下图显示了整个数据集是如何被划分为训练集（Training）、验证集
（Validation）、测试集(Testing)的：

#+BEGIN_QUOTE
图7.15：神经网络工具箱数据集划分比例
#+END_QUOTE

前面的章节中已经详细叙述了划分为三个数据集的原因，即每个数据集的
目的是什么。这里我们再简要复习一遍：

- 训练集（Training）：训练集中的样本用于求解模型参数。对神经网络
  意味着权重参数和偏置项
- 验证集（Validation）：在训练完毕后，验证集的样本将被输入参数，
  模型在验证集上的表现被用于衡量模型对训练集的拟合能力。如果验证
  集表现不足，证明当前模型不具备拟合数据集的能力，需要重新设计模
  型进行训练、验证
- 测试集（Testing）：模型在训练集样本上的表现被视为对模型泛化能力
  的最终测试。通过观察测试集误差，我们能够观察到过拟合、拟合不足
  等问题。测试集表现是评估模型好坏、挑选最终模型的标准

至此我们已经介绍完毕使用'nntb_snp'进行神经网络建模的整个流程。但
是在读者动手操作前，我们需要学习最后一项功能：样例数据集。我们之
前提到，数据收集的工作通常实在使用MATLAB前已经完成的，这意味着存
储数据的格式必须适合导入到MATLAB中。在学习阶段，读者往往还没有实
际问题的数据集。无须担心，MATLAB提供了大量样本数据集供读者测试模
型、学习工具箱使用。

对'nntb_snp'MATLAB提供了几个样例数据集。在应用到实际数据集前，我
们可以先通过这些样本数据集来建立、调试我们的模型、程序代码。我们
可以使用如下代码查看可用的数据集：

#+BEGIN_QUOTE
代码
#+END_QUOTE

上面这个命令展示了所有神经网络工具箱适用的数据集名称及其概述。注
意，所有数据集的命名格式都是 ~name_dataset~ 。这些数据集中都会存
在两个变量： ~nameInputs~ 和 ~nameTargets~ 。例如我们可以通过如下
代码加载包含鲍鱼壳大小信息的数据集：

#+BEGIN_QUOTE
代码
#+END_QUOTE

这段代码将会加载 ~abaloneInputs~ 和 ~abaloneTargets~ 到工作空间中。
如果你希望使用其它变量名命名之前两个变量，你可以使用如下代码：

#+BEGIN_QUOTE
代码
#+END_QUOTE

上面这段代码将会加载输入变量、目标变量到两个名为 ~Input~ 和
~Target~ 的变量中。接下来我们可以使用如下命令获取数据集的详细描述：

#+BEGIN_QUOTE
代码
#+END_QUOTE

下图显示了上面操作在MATLAB环境中的结果：

#+BEGIN_QUOTE
图7.16：加载 ~abalone_dataset~ 后MATLAB结果
#+END_QUOTE

如图7.16所示，在数据集描述中我们可以获取例如特征值数量、特征值名
称、变量列表等信息，并且还简单列举了可以使用数据集的情形。


** 工具箱的用户界面（GUI）

GUI的全称是 Graphical User Interface，即图形用户界面，它通过各种
按钮、选项与用户进行可视化交互，并将结果也通过图形显示出来。由于
其易于理解，通过GUI界面，即使是初学者也可以完成非常复杂、极具挑战
的任务。但是读者需要清楚的是，与这些按钮、选项的交互只是表面现象，
这些可视化工具仍然是按照用户输入的参数，调用工具箱中的函数进行运
算，这些函数与我们编写程序、阅读帮助文档时用到的函数完全相同。简
单地说，相同参数情况下，通过GUI进行的运算和通过编写代码进行的运算
没有任何区别。

为了使神经网络建模尽可能简单，'nntb_snp'提供了一系列GUI功能用户使
用。所有这些界面都通过 ~nnstart()~ 函数开始运行，这个函数是一系列
GUI例如拟合、模式识别、聚类、时间序列分析等GUI的入口：

#+BEGIN_QUOTE
代码
#+END_QUOTE

上面的代码将会打开名为 ~Neural Network Start~ 的界面，如下图所示：

#+BEGIN_QUOTE
图7.17：神经网络工具箱初始界面
#+END_QUOTE

这个界面提供给我们工具箱所有功能的入口，在图7.17中，我们可以看到
通过这个界面我们可以解决如下四类问题：

- 数据拟合 ~nftool~
- 模式识别 ~nprtool~
- 聚类 ~nctool~
- 时间序列分析 ~ntstool~

工具箱对上面每类问题都提供了非常简便、易于使用的GUI。其中第一个工
具 ~nftool~ 用于解决拟合问题。在拟合问题中，神经网络被用于实现由
任意一系列输入数据到输出数据组成的数据集的映射函数。 ~Neural Fitting~
APP 能够帮助用户选择数据集，创建和训练神经网络，以及通过均方误差、
回归分析来评估训练结果。下面章节来我们将详细讲述拟合APP。

第二个工具 ~nprtool~ 用于协助用户处理模式识别问题。在模式识别问题
中，我们需要使用神经网络，对输入数据按照某种类别标签进行分类。同
样，这个工具提供了一系列GUI帮助我们选择数据集，创建和训练神经网络，
以及通过'confmat_snp'和'cren_snp'来评估训练结果。

第三个工具 ~nctool~ 用于处理聚类问题。在聚类问题中，我们使用神经
网络通过衡量样本间的相似程度对数据集进行聚类。同样，这个工具箱提
供了丰富的GUI帮助用户选择数据集，创建和训练神经网络，以及通过一系
列可视化图表来评估训练结果。

最后一个工具 ~ntstool~ 用于解决复杂动态系统中，非线性时间序列的相
关问题。动态神经网络工具箱可用于解决拟合非线性函数拟合、预测、过
滤等问题。时间序列分析的一大类任务就是基于历史数据对未来数据进行
预测，这个工具使我们能够解决如下三类问题：

- 带有外生变量的非线性自回归问题
- 非线性自回归问题
- 非线性函数拟合


** 使用神经网络进行拟合

数据拟合是指根据数据集中的样本和目标值关系，使用数学模型构建从输
入到输出的映射关系，即从数据集的样本中学习代表其映射关系的函数。
其中最简单的一种用途就是通过拟合的函数，应用插值法填补空缺数据，
即给定某个数据集中缺失的输入，通过拟合的函数计算出新的样本。这里
我们谈到数据拟合时，多指回归问题，即函数能够多大程度逼近尽可能多
的样本点。除用于插值外，数据拟合结果所得函数同样可以被用于可视化
数据集、基于历史数据预测未来以及发现多个变量间的联系。

#+BEGIN_QUOTE
图7.18：使用线性函数对数据集进行拟合
#+END_QUOTE

前面回归分析的章节中我们已经介绍过如何使用回归方程对数据集中样本
构成的曲线进行拟合。通过之前使用的模型我们发现，这些模型并不总是
有效的，没有任何模型能够完美拟合数据集中全部样本点，对于拟合效果
较差的模型，我们甚至无法通过拟合结果对未来趋势进行预测。这些非常
复杂的拟合场景往往是由两大类原因造成的。第一种是问题、数据集本身
就非常复杂，难以拟合。第二种原因则更加常见的，真实数据在收集过程
中无法避免会受到噪声污染，有些噪声是正常现象，代表了样本个体的特
征。更加隐蔽的是，有些“噪声”的出现并非因为样本个体所造成的波动，
而是问题背后的原因包含诸多不为人所知、我们无法观测到的变量（例如
股价波动），被误认为噪声。无论哪种现象，传统的频率学派、统计学派
的模型都非常难以应对这种级别的复杂度。然而'anns_snp'虽然数学上极
为简单，但是通过大规模、层次化运算，具有极为强大的拟合能力，非常
善于处理此类问题，在实际应用中往往具有极好的效果。

对神金网络，所谓拟合就是指训练阶段，通过输入数据集中的样本求解链
接权重参数的过程。一旦参数求解完毕，训练后的神经网络就已经是一个
从输入数据到输出数据的映射函数，构建了从样本特征向量到目标值的映
射关系，并可以被应用于之前提到的各种应用场景。

我们之前讲过，'nntb_snp'大体上分为四种调用方法，其中最常用于完成
拟合问题的方法是：

- 通过GUI ~nftool()~ 调用
- 通过工具箱中函数直接编程使用

对于初学者，我们最好从 ~nftool~ 这个APP开始学起。因为这些已经被编
辑好的图形界面，已经集成了MATLAB封装好的、使用神经网络建模所需的
各种流程、参数设置。通过GUI学习能够极大程度降低学习成本。同时需要
再次指出的是，用户与GUI的交互如鼠标点击等，同样会生成MATLAB代码，
无论初学者还是专家，通过对这些代码的学习，也同样极大降低了之后脱
离GUI，直接使用函数编写程序的学习成本。

GUI已经提供了我们一系列精准排序后的对话框，我们只需要按照顺序进行
点击按钮、通过菜单选择选项，就能使用GUI完成与手工编写程序完全相同
的工作。换句话说，我们无需了解构建、训练神经网络的全部代码再手工
编写程序。

更好的是，一旦我们完成了GUI的全部操作，我们可以选择让GUI自动生成
它所调用的全部代码。通过学习这些代码，我们能够理解之前一系列与图
形界面交互背后进行的，代码级别的详细调用流程。通过这种方法我们可
以非常快速的学会在什么步骤怎样地使用什么函数。

下面我们开始应用APP操作神经网络。与之前相同，无论学习什么模型，我
们首先需要导入数据集。这里为了简便，我们使用MATLAB提供的样本数据
集。在MATLAB提供了诸多数据集，其中每个数据集都专门尤其最适合的应
用场景。我们可以通过 ~help~ 命令查看这些帮助文档：

#+BEGIN_QUOTE
代码
#+END_QUOTE

上面代码会按照类别输出诸多数据集信息。这里我们选取几个与曲线拟合
相关的数据集进行展示：

~simplefit_dataset~ ：简单的用于举例拟合场景的数据集
~abalone_dataset~ ：鲍鱼壳周长数据集
~bodyfat_dataset~ ：体脂数据集
~building_dataset~ ：建筑耗能数据集
~chemical_dataset~ ：化学物质探测器数据集
~cho_dataset~ ：胆固醇数据集
~engine_dataset~ ：引擎数据集
~vinyl_dataset~ ：乙烯溴化物数据集

当然，除了MATLAB提供的样例数据集，我们也可以使用我们要解决的实际
问题的数据集。通过学习样例数据集能够帮助我们很好地了解神经网络APP
规定的输入数据、目标数据格式，这能够对我们收集实际样本时进行指导。
实际样本数据收集完成后，我们可以根据第二章中所学到的知识将数据导
入到MATLAB。


*** 如何使用 Neural Fitting APP (nftool)

在拟合问题中，神经网络本身作为映射函数，能够建立从输入数据到目标
数据的映射关系。 ~Neural Fitting APP~ 能够帮助我们选择数据、建立、
训练神经网络，并通过均方误差和回归分析衡量模型泛化能力。为使用
~Neural Fitting APP~ ，我们首先在MATLAB的命令行对话框中输入如下代
码：

#+BEGIN_QUOTE
代码
#+END_QUOTE

接下来会打开 ~Neural Fitting APP~ 的欢迎页面：

#+BEGIN_QUOTE
图7.19： ~Neural Fitting APP~ 欢迎页面
#+END_QUOTE

~Neural Fitting APP~ 的欢迎页面对此APP的主要功能进行了简要介绍，
并提醒我们APP中已经集成了一些可立即使用的例子。更重要的是，它对能
够创建的神经网络结构就行了描述。

~Neural Fitting APP~ 使用一个包含一个隐含层的前向传播神经网络建立
从输入到输出的映射函数。在前向神经网络中，链接只能够前向传播计算
结果，不会形成从后向前的回环结构。因此在这种网络中，信息只能向单
一的方向流动，即从输入层向输出层的方向流动，中间不会出现环状链接。
在训练阶段，只有链接权重会被改变。

#+BEGIN_QUOTE
图7.20：前向传播神经网络结构图
#+END_QUOTE

在欢迎页面的底层有一些可以操作的按钮。通过点击右下角的按钮我们可
以向前、向后浏览不同阶段的操作页面。如当前页面所示，我们点击 Next
按钮进行下一步。

一个新的窗口会被打开（见图7.21）这里我们可以选择要被拟合的数据集。
这里有两个选项：

- ~Get Data from Workspace~ 从工作空间中获取数据
- ~Load Example Data Set~ 加载MATLAB提供的样例数据集

第一个选项使我们能够导入自定义的实际数据集。数据集必须至少包含两
个变量，一个变量保存特征值矩阵，一个变量保存目标向量。如之前所说，
为了方便理解工具箱规定的数据而是，读者可以先加载样例数据集，学习
一下MATLAB提供的样例数据集中是如何组织数据的。

#+BEGIN_QUOTE
图7.21：选择数据对话框
#+END_QUOTE

从图7.21中我们可以看到，在 ~Get Data from Workspace~ 区域中，我们
有两个区域需要进一步填充：

- ~Input data to present to the network~ 需要输入神经网络的数据变
  量
- ~Target data defining desired network output~ 神经网络目标变量

这两个区域都包含用于选择已经被加载到工作区的变量的下拉菜单，或者
我们可以通过点击省略号按钮，使用MATLAB导入数据功能新导入数据到工
作区。设定好输入、目标数据后，我们还需要最后指定一下数据集的排列
方式：

- ~Matrix columns~ 每列代表一个样本
- ~Matrix rows~ 每行代表一个样本

默认选项是 ~Matrix columns~ ，代表输入变量中，每列代表一个样本的
特征向量。如果选择 ~Matrix rows~ ，则表示矩阵中每行代表一个样本。
至此数据集及其格式已经全部设置完成。窗口下方的选项使我们在这步中
能够加载MATLAB提供的样例数据集。对于初学者，我们强烈建议先通过加
载样例数据集来进行学习，因为这样可以避免初学者进行数据清洗、格式
整理等与神经网络完全无关的数据预处理工作。通过使用样例数据集我们
可以以最快的速度、最高的质量熟悉神经网络APP。这里我们点击
~Load example dataset~ 按钮，会弹出加载数据对话框：

#+BEGIN_QUOTE
图7.22：加载数据对话框
#+END_QUOTE

在这个对话框中，选择了可以加载的全部数据集。对话框右边对选中的数
据集进行了简要介绍。这里我们选取 ~engine_dataset~ 数据集。这个数
据集可被用于训练一个，基于发动机的燃料和转速数据，能够预测发动机
扭率的神经网络。这个数据集包含以下两个变量：

- ~engineInputs~ 大小为 $2\times 1199$ 的数值型矩阵，包含两个特征
  值：燃料数据、速度数据
- ~engineTargets~ 大小为 $2\times 1199$ 的数值型矩阵，包含需要预
  测的两个目标变量：扭率、氮氧化物排放量

我们总结下上面为导入 ~engine_dataset~ 所进行的操作：我们首先在图
7.22显示的对话窗口中点击 ~Import~ 按钮。之后我们会回到图7.21的对
话窗口。至此APP已经自动向MATLAB中加载了两个矩阵： ~engineInputs~
和 ~engineTargets~ 矩阵。同时，这些矩阵的相关设置也已经被自动显示
在对话窗口的 ~Get Data from Workspace~ 区域。至此我们可以单击
Next 按钮继续进行下面的操作：

#+BEGIN_QUOTE
图7.23：验证和测试神经网络对话窗口
#+END_QUOTE

在图7.23的对话窗口中，工具箱会自动对数据集进行分割。按照 $70\%$
$15\%$ 和 $15\%$ 的比率将数据集分为训练集（Training）、验证集
（Validation）和测试集（Testing）三个部分。其中训练集的比率是固定
不变的，然而用户可以随意调整其它两个数据集的比例。

#+BEGIN_QUOTE
小贴士：这里再次帮助读者回顾三个数据集的作用：训练集用于求解神经
网络中的参数；验证集能够衡量训练后的模型对训练集拟合结果的好坏，
如果验证集效果不达标，那么需要重新设计神经网络、进行训练；测试集
能够被用来衡量神经网络的泛化性能，神经网络在测试集上的表现是衡量
其性能好坏的最终标准。
#+END_QUOTE

接下来我们点击 Next 按钮，进入 ~Network Architecture~ 对话框，如
下图所示：

#+BEGIN_QUOTE
图7.24：神经网络结构对话框
#+END_QUOTE

对话框中显示了默认的神经网络结构：包含一个隐含层的前向传播神经网
络，并且使用 ~sigmoid~ 函数作为激活函数；输出层则使用简单的线性函
数作为激活函数。其中，隐含层默认包含10个神经元。当训练结果表现不
尽如人意时，我们可能可以通过增加神经元数量得到在训练集上拟合效果
的改进（但过多神经元可能出现过拟合问题）。在设置好隐含层大小后，
我们可以继续点击 Next 按钮，进入 ~Train Network~ 训练神经网络对话
窗口，如下图所示：

#+BEGIN_QUOTE
图7.25：训练神经网络对话窗口
#+END_QUOTE

在这个对话窗口中，我们可以选择三种算法中的一种作为神经网络的训练
算法：

- *Levenberg-Marquardt* (~trainlm~) ：适用于绝大多数神经网络
- *Bayesian Regularization* (~trainbr~)：对于小数据集、噪声较多的
  数据集适用，但训练时间更长
- *Scaled Conjugate Gradient* (~trainscg~)：适用于大数据集。这个
  算法使用梯度作为神经网络更新权重的依据，而非雅克比矩阵，因此在
  内存使用上更具效率

我们选择 *Levenberg-Marquardt* 作为神经网络训练算法。一旦选择完训
练算法，我们可以点击 Train 按钮开始神经网络训练。训练过程将不断迭
代，直至验证集上的误差连续6次迭代都不再下降。当训练结束后，
~Results~ 区域中会显示验证集上的 ~MSE~ 和 ~R~ 值作为对训练结果好
坏的衡量。

#+BEGIN_QUOTE
小贴士： ~Mean Sqared Error (MSE)~ 是神经网络输出向量与目标向量加
权平均后的均方误差， ~MSE~ 值越小代表训练效果越好。 ~Regression (R)~
则衡量输出向量与目标向量的相关性。 $1$ 代表非常相关， $0$ 则代表
相关性极低。因此相关性系数越大训练效果越好。
#+END_QUOTE

如果我们对训练结果不满意，我们可以重新训练（随机初始化结果会影响
神经网络的表现，因此每次训练结果不同），或者更改神经网络结构后再
次训练。我们可以通过点击 Back 按钮回到设置神经网络参数的对话框，
更改完毕后再点击 Next 回到训练对话窗口。这些操作将赋予神经网络新
的初始化权重，或者新的结构，并有可能带来拟合效果上的改进。此外，
在训练神经网络对话框的 ~Results~ 部分，我们还有三个按钮：Plot Fit
（绘制每次一训练迭代中模型表现）、Plot Error Histogram（绘制误差
箱状图）和 Plot Regression（绘制相关性系数图）。这些图表能够提供
给我们的信息对评估训练结果至关重要。例如，我们可以通过绘制误差箱
状图，如下图所示，来进一步研究训练算法产生的结果：

#+BEGIN_QUOTE
图7.26：误差箱状图
#+END_QUOTE

在误差箱状图中，蓝色的条形代表训练数据，绿色的条形代表验证数据，
红色的条形代表测试数据。这幅图可以让我们看清楚误差的分布状态。如
果误差分布呈正态分布，则意味着训练结果较好。此外，误差柱状图还能
够让我们观察到奇异值，即训练误差显著大于平均水平的样本点。另外我
们还可以通过绘制相关性系数图来评价训练结果：

#+BEGIN_QUOTE
图7.27：相关性系数图
#+END_QUOTE

相关性系数图中显示了以目标向量为横轴，输出向量为纵轴绘制的训练集、
验证集、测试集及全体数据集的样本点相关性系数图。对于一个表现优秀
的系统，相关性的分布应该尽可能靠近 $45$ 度角，即模型输出与目标值
基本相等。在上图中，我们可以看出模型拟合效果非常优秀，因为在四幅
图中所有 $R$ 值都高于 $0.99$ 。与之前分析方法作用相同，我们可以通
过相关性系数图评价训练结果好坏，如果结果不达标，则可以返回之前步
骤重新训练神经网络。

点击当前对话窗口中的 Next 进入下一界面， ~Evaluate Network~ 评估
神经网络算法窗口将会被打开，如下图所示：

#+BEGIN_QUOTE
图7.28：评估神经网络窗口
#+END_QUOTE

在当前窗口中，你可以通过在测试集上运行之前训练好的神经网络，来评
估当前神经网络的泛化能力。当前界面集成了以下工具：

- 工具箱提供了多种评估泛化能力的方法
- 加入新的数据，扩充现有的测试集进行测试
- 重新训练神经网络
- 添加更多神经元
- 使用更大的训练集

#+BEGIN_QUOTE
小贴士：与之前的模型相同，如果训练集、验证集上的表现很差，我们可
以通过增加神经元数量对结果进行改善。然而在训练、验证集上有良好表
现，而测试集上表现很差的神经网络表示出现了对训练集的过拟合现象。
我们可以通过减少神经元数量避免这一现象。如果交替出现以上两个问题，
说明当前一层隐含层的神经网络不足以拟合数据集，需要使用更加深度的
神经网络进行拟合。
#+END_QUOTE

点击 Next 按钮进入下一界面。 ~Deploy Solution~ 部署解决方案页面将
会被打开。通过这个页面我们可以导出当前训练好的神经网络模型，以便
能够重复使用、用于生产环境。部署页面如下图所示：

#+BEGIN_QUOTE
图7.29：部署解决方案对话窗口
#+END_QUOTE

这里提供了四种部署方式：

- 导出支持 ~matrix~ 和 ~cell~ 数据类型的MATLAB函数（Generate a MATLAB function with matrix and cell array argument
  support）
- 导出仅支持 ~matrix~ 类型，不支持 ~cell~ 类型的MATLAB函数（Generate a MATLAB function with matrix-only argument (no cell
  array support)）
- 导出 Simulink 图（Generate a Simulink diagram）
- 导出神经网络结构图（Generate a graphical diagram of the neural
  network）

通过这些选项，我们能够生成可复用的MATLAB函数，或者 Simulink 图，
用于在MATLAB的 Simulink 产品中对神经网络进行仿真，这些导出的结果
能够直接被MATLAB编译成独立的应用程序，并在其它应用场景中直接使用。
此外，正如之前提到的，在这里生成的MATLAB代码脚本，或是 Simulink
图，是非常好的学习资源，能够帮助我们快速理解GUI背后所进行的操作，
快速学习神经网络工具箱的使用流程。我们可以直接点击对话框中右侧的
按钮进行选择（MATLAB函数，只支持 ~matrix~ 类型的MATLAB函数，
Simulink 图，神经网络结构图）。

点击 Next 按钮，我们将进入 ~Save Results~ 结果保存页面，弹出的对
话窗口如下图所示：

#+BEGIN_QUOTE
图7.30：结果保存对话窗口
#+END_QUOTE

这里提供了一下几种保存方法：

- 按照之前用户在GUI中的设置，生成对应的MATLAB代码文件（Generate a
  script to train and test a neural network as you just did with
  this tool）
- 除用户设置外，在脚本中添加其余设置及示例代码（Generate a script
  with additional options and example code ）
- 将数据保存在工作空间中（Save Data to Workspace）

我们能够通过点击相应的按钮，生成之前图形界面操作背后所调用的工具
箱中的函数代码。另外我们可以将中间过程、计算结果等数据保存在当前
工作空间中。我们可以选择需要保存的变量，并在文本框中对其进行重命
名，设置完毕后点击 Save Results 按钮进行保存。所有操作完成后，我
们点击 Finish 按钮退出APP。

多么神奇啊！我们几乎啥事没干就完成了构建神经网络的任务，能够这么
轻松多亏MATLAB及其提供的 ~nftool~ APP（还要感谢原作者令人震惊的扯
淡功力）。


*** 脚本分析

之前我们不断重复，虽然我们表面上是在点击GUI，与图形界面进行交互，
但本质上就是在通过图形界面对话窗口，对MATLAB已经封装好的工具箱函
数进行可视化的调用。调用的结果与直接使用工具箱函数编写MATLAB代码
没有任何区别。也就是说，我们通过研究与GUI的交互所产生的MATLAB代码，
就能够学会如何脱离GUI，直接使用工具箱函数编写程序。通过这种方法可
以大大简化学习难度，我们可以非常清晰地看到使用MATLAB构建神经网络
需要经过哪些步骤，每个步骤需要按什么顺序调用什么函数。更好的是，
这些GUI生成的代码是可以直接被MATLAB执行的，具有极强的可复用性。通
过修改这些代码，我们能够按照实际问题的具体需求对其个性化定制。接
下来我们学习下本章一系列操作所生成的代码：

#+BEGIN_QUOTE
代码
#+END_QUOTE

在习惯了可视化APP的简便操作后，一下子看到这么多代码读者可能会很头
疼。但是请别慌张，如果你仔细阅读代码，会发现这些代码实际是以极为
精炼的语言，简短、精确地描述了我们之前诸多鼠标、键盘操作所完成的
内容。事实上，我们整章诸多图形界面操作，使用上面的代码表述只有短
短的17行！这充分体现了尽管直接编写代码更加抽象、对初学者难度较高，
但是是高效利用MATLAB的最好方法！接下来我们来一行行分析上面的代码。
首先我们来看头两行代码，它们定义了神经网络的输入矩阵、目标向量：

#+BEGIN_QUOTE
代码
#+END_QUOTE

第三、四行代码则负责构建神经网络。其中第三行代码定义了隐含层神经
元的数量为 $10$ 个。这正是前面小节中我们在对话窗口中选用的默认数
值。第四行调用工具箱函数 ~fitnet()~ 正式创建了神经网络。我们之前
讲过， ~nftool~ 的默认模型是只包含一层隐含层、使用 ~Sigmoid~ 函
数作为隐含层激活函数，使用线性函数作为输出层激活函数的前向传播神
经网络。这个神经网络根据之前定义的目标向量 ~engineTargets~ 的大小，
会默认创建两个输出神经元（分别输出扭率和氮氧化物排放量）：

#+BEGIN_QUOTE
代码
#+END_QUOTE

第五到七行则对数据集进行定义，它们定义了三个数据集（训练、验证、
测试集）在整个数据集中所占比例：

#+BEGIN_QUOTE
代码
#+END_QUOTE

第八行对神经网络进行训练。在训练过程中，工具箱会默认打开一个名为
~Neural Network Training~ 的窗口。这个窗口将展示整个训练过程，例
如误差的变化过程，通过这个窗口用户还可以随时停止训练。这里我们使
用了 *Levenberg-Marquardt* 算法即默认算法 ~trainlm~ 作为神经网络
训练算法。我们之前提到过，除了上面的算法工具箱还提供了另外两个算
法 *Bayesian Regularization* （ ~trainbr~ ） 和 
*Scaled Conjugate Gradient* （ ~trainscg~ ）。如果我们想要更改默
认训练算法，只需要使用命令 ~net.trainFcn = 'trainbr'~ 或者 
~net.trainFcn = 'trainscg'~ ，这里我们使用默认值 ~'trainlm'~ 即可。

#+BEGIN_QUOTE
代码
#+END_QUOTE

第9到11行对训练好的神经网络进行评估。在训练结束后，用户可以使用神
经网络对任意样本的特征向量计算输出向量。下面的代码利用 ~outputs~
神经网络输出值计算其与 ~targets~ 即数据集中目标向量（真实值）的误
差 ~errors~ ，并进一步将其用于计算神经网络泛化能力指标
~performance~ ：

#+BEGIN_QUOTE
代码
#+END_QUOTE

第十二行代码则生成了神经网络结构图：

#+BEGIN_QUOTE
代码
#+END_QUOTE

最后一段代码负责绘制之前GUI中使用的一系列图表：

#+BEGIN_QUOTE
代码
#+END_QUOTE

#+BEGIN_QUOTE
小贴士：我们之前说过，多次重复神经网络建立、训练的过程会得到多个
不同结果，这是由于模型权重参数初始化每次都不同造成的。但实际上，
每次重复执行时，三个数据集（训练、验证、测试集）包含的样本也不相
同。但这与工具箱有关，而与神经网络模型本身无关。
#+END_QUOTE

** 总结

本章我们介绍了如何使用'anns_snp'模拟人脑思考。我们首先简介了神经
网络的概念，并将生物学概念与数学模型概念进行了深入的比对。接着我
们选取了一个非常简单的神经网络结构，来为读者介绍神经网络的使用流
程，即如何定义输入输出、如何定义神经网络架构、如何选取激活函数、
如何训练神经网络以及如何评估神经网络。

我们学习了如何选取隐含层的数量，以及每个隐含层所包含的神经元的数
量，并且学习了训练算法。接着我们学习了'nntb_snp'，展示了它提供的
诸多算法、应用场景、预训练模型、样例数据集，以及能够帮助我们建立、
训练、测试、仿真和可视化的APP。我们介绍了GUI的欢迎界面，并指出这
个APP包含4大应用：拟合、模式识别、聚类和时间序列分析。

最后我们以拟合数据集举例如何使用神经网络GUI。我们学习了如何使用
~nftool~ 。最后我们根据GUI操作生成的脚本，分析了如何使用MATLAB代
码构建神经网络。

在下一章中，我们将讲述如何使用MATLAB进行降维。我们将介绍特征选择
和特征提取的区别。我们还将学习如何正确的对原始数据集的冗余信息进
行降维处理。我们将学习诸如主成分分析和因子分析的模型方法。
