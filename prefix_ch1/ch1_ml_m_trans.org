* 第一章：MATLAB机器学习初步
“为什么你这个机器就听不懂我的命令呢？”“什么叫‘你这个机器’？你当我
是个猴儿吗？”。这是电影《机械纪元》中主演与机器人的一段对话。在这
部电影中，机器人被设定有两条不可更改的原则：不可以伤害人类；不可
以自我修复。为何人类要限制机器人的自我修复能力呢？因为有强大自我
学习能力的机器人，也许终将统治这个世界。

至少，这是电影中发生的事实。

但问题的关键在于，到底什么是“自我学习能力”呢？暂且定义为，机器、
算法具有从一系列与外部环境的互动中，改善自身表现、提高自身成绩的
能力。因此，这种能力能够帮助人类从大数据中解决某些特定问题，例如
知识提取。本章我们将对机器学习的概念进行简要介绍，接着我们将快速
浏览一些基本算法。除此之外，本章也会对MATLAB基础知识进行简介。最
后，我们将精要学习MATLAB提供的几个强大的机器学习工具箱。

本章覆盖了一下主题：

- 展示MATLAB机器学习工具箱，包括分类、回归、聚类和深度学习工具箱。
  同时也将展示用于模型训练和代码生成的APP、交互图形界面（GUI)
- 对一些非常流行的机器学习算法进行简介，并说明各个算法的适用场景
- 理解统计学和线性代数在机器学习中的作用

在本章末尾，你将理解不同的机器学习算法以及其在MATLAB中的实现工具。

** 机器学习基础
给机器学习下定义是件非常困难的事。我们先来听听机器学习领域的大牛
们是如何定义的：

#+BEGIN_QUOTE
机器学习：研究如何计算机在未被明确编写指令情形下，自主学习的领域
-- Arthur L. Samuel(1959)
#+END_QUOTE

另一种定义是：

#+BEGIN_QUOTE
“机器学习”指使系统能够在下一次，更有效率、更好表现地执行同一任务，
或与样本集（数据集）属于同一分布的任务，的自适应能力 -- Herbert
Alexander Simon (1984)
#+END_QUOTE

以及另一种：

#+BEGIN_QUOTE
假设对于 *任务* $T$ ，有 *经验* $E$ 以及 *评价指标* $P$ ，那么学
习指的是能够在执行 *任务* $T$ 时通过学习 *经验* $E$ ，以提高*评价
指标* $P$ 的能力 -- Tom M. Mitchell(1998)
#+END_QUOTE

这些引用的共同点是，他们都将指向了一种没有任何外界帮助的情况下，
自助学习的能力。这正是许多情况下我们人类进行学习的方式，那为何我
们不能让机器、算法也具有同样的能力呢？

#+BEGIN_QUOTE
图1.1 机器学习历史
#+END_QUOTE

机器学习是一门由计算机科学、统计学、神经学和控制理论衍生出的交叉
学科。它的出现在一些领域中扮演了至关重要的角色，并且已经彻底地改
变了人们对编程的理解。如果之前我们要解决的问题是，“如何给计算机编
写程序”，那么现在我们的问题是，“如何使计算机自己给自己写程序”？

因此，机器学习可以被视为赋予计算机“智能”的基础理论。

跟我们大多数人的直觉一致，机器学习的发展是与神经学的研究紧密相关
的。正如我们人类直觉、智能的基础是大脑及其中的神经原，目前我们认
为'anns'可以作为计算机进行决策的基础。

机器学习方法使我们能够自动从数据集中拟合能够描述此数据集的模型。
例如，给定数据集，我们可以从中自动建立输入数据到输出数据的映射关
系。一大类路径是参数估计方法。参数估计是指，我们首先假设输入数据
到输出数据间存在某种形式的映射关系，例如高斯分布，然而我们并不知
道这种映射关系的具体参数，因此需要通过在学习数据集中的信息对参数
进行拟合。从逻辑学、哲学的角度而言，这些方法可分为演绎(deduction)、
归纳(induction)和“强盗”(abduction)，他们的关系如下图所示：

#+BEGIN_QUOTE
图1.2 Peirce’s三角，三种推理方法的关系
#+END_QUOTE

从已观测到的数据集中抽象出普遍适用的法则称为归纳（induction)；与之
相反，演绎(deduction)是指应用已知的法则，对新观测到的数据进行预测。
归纳是科学研究过程中的基础方法，它使我们能够从观测到的现象中总结
出普遍适用的规律。

已观测到的现象是指能够描述这一现象的一系列指标，即变量。根据这些
指标、变量总结出的模型（估计出的模型的参数），可以继续用于新观察
到的数据的预测。整个从已观测数据集总结模型、使用模型对新加入数据
进行预测的过程，成为'infe'。

#+BEGIN_QUOTE
这部分作者写的过于晦涩、且并非ML经典分类方法，因此在翻译时我加入
了一些例子说明，和其它经典教材上(上的解释)的解释、翻译参考中文教
材（机器学习周志华版）
#+END_QUOTE

因此，归纳学习的精髓在于从已观测数据中寻找，可被'gen'到未观测数据
集（新加入的数据），以进行预测的模型。例如，基于过往股票价格数据
以及涨跌情况，我们可以对一个线性分类方程进行参数优化，并将优化后
的模型用于预测未来股票的涨跌情况。所谓'gen'性能好坏，即从历史数据
中得到的模型，在新数据上预测结果的优劣。这种预测并非总能奏效，但
至少我们可以希望得到好的结果。

归纳学习可以被简单地分为如下两类：

#+BEGIN_QUOTE
PRML上没有提到过这种分类方法，感觉更科学的分类方法、原著作者在这
里想表述的是监督学习和非监督学习
#+END_QUOTE

- 通过历史数据学习(learning by example)：例如对'bc'问题，通过学习
  正样本（positive samples)——即属于某分类的样本，以及反样本
  （negative samples)，能够获得关于这个分类问题的知识，即模型或参
  数
- 通过规律学习(learning reqularity)：此类方法目标是在给定数据集中，
  寻找样本间的“规律”，即共同特征

下图展示了归纳学习的分类：

#+BEGIN_QUOTE
图1.3 归纳学习的类型（这块干脆去了算了）
#+END_QUOTE

可能很多读者有这个疑问：为什么机器学习算法要优于传统算法、模型
（如基于规则的 rule-based 方法）呢？有很多原因和视角可以解释这个
问题：

- 人类对许多问题本身已很难描述：例如，我们很容易认出我们熟悉的人
  的声音，但是应该没人能够系统地描述出，他识别这些声音所经过的运
  算步骤
- 大数据：例如，当需要从不同环境下拍摄的文档相片中识别文字时，人
  们很难穷举所有可能的参数组合。适用于某种环境下的参数设置，往往
  无法直接应用到其它环境上
- 缺乏理论：例如预测股票价格
- 需要在大数据中进行个性化定制：例如购物网站的推荐算法需要实时给
  每个买家推荐根据其个人兴趣选择的商品

下图展示了归纳学习和推测学习的异同：

#+BEGIN_QUOTE
图1.4 归纳学习、推测学习流程图
#+END_QUOTE

** 机器学习算法分类

机器学习算法的魔力源于算法的'gen'能力，这正是过去这些年中科学家们
着力更新、改进的内容。这些算法可以根据使用的输入数据、训练方式以
及学习到的模型的输出结果，被分为三类：

- 监督学习：这类算法同时使用样本的特征集合、每个样本对应的标签的
  集合作为输入数据，以建立从特征集合到标签的映射关系，即模型与参
  数
- 非监督学习：这类算法只需要输入样本的特征集合，不需要样本事先被
  标注。学习的结果往往是描述这个数据集样本间某种关系的模型。一个
  经典的例子是搜索引擎可以通过网页间的相互引用关系、文本内容等，
  自动将不同网站进行归类
- 强化学习：这种算法能够通过多次迭代、观察每次迭代后环境产生的反
  馈进行学习。事实上，每次迭代后的输出结果、模型采取的行动，都会
  都环境产生影响，而环境也会针对这些影响进行反馈。这类算法多被用
  于游戏角色开发、语音识别和文本识别上

下图描述了不同机器学习算法间的关系：

#+BEGIN_QUOTE
图1.5：机器学习算法分类
#+END_QUOTE

** 监督学习
监督学习同时使用样本的特征集合 $X$ 、每个样本对应的标签的集合 $O$
作为输入数据，以建立从特征集合 $X$ 到标签 $O$ 的映射关系，即模型
与参数。用于求解模型、参数的数据集，被称为'ts'。监督学习的训练流
程如下图所示：

#+BEGIN_QUOTE
图1.6 监督学习训练流程 （Output 后面应该是 O 不是 X）
#+END_QUOTE

所有的监督学习算法的训练都基于以下假设：如果数据集中所有样本都是
从同一分布 $P(A)$ 中抽样得到的，通过向监督学习算法输入足够多的样
本，算法优化后得到的分布 $P(B)$ 能够无限逼近真实分布 $P(A)$。

在用于预测问题，监督学习假设，相似的输入应当有相似的输出。即将模
型 $P(B)$ 在新数据上应用时，其输出结果应当与真实分布 $P(A)$ 相似。

#+BEGIN_QUOTE
下面三段我并不认同啊，是否可以不终于原著？
#+END_QUOTE

总的来说，在实际应用中这两个假设不总是成立的。很显然，这种算法的
最终表现很大程度上取决于输入数据集的质量。如果输入数据集只包含了
少量样本，那么训练得到的模型就没有学习到足够经验进行正确预测。相
反，过多的冗余样本将导致优化的模型过于复杂，因此将降低模型的执行
速度。

#+BEGIN_QUOTE
下面这段话太片面，频率视角下、概率视角下的最大似然估计方法、贝叶
斯方法中的高斯分布（单极值点）的确存在这个问题。但是对于多数模型，
添加先验概率后的后验概率分布极大程度解决这个问题。对于多极值点的
模型，高斯混合分布是鲁棒性非常高的。
#+END_QUOTE

此外，实际开发中我们发现，监督学习算法对数据集中的噪声、奇异值非
常敏感，即使很小比例的奇异值，也将导致整个系统产生极大偏误，并作
出错误预测。

在监督学习中，我们可以根据输入数据特征、学习任务的不同，将其分成
两类。当我们需要输出离散的类别数据、对数据集中的样本进行归类时，
此类问题被称为分类问题。当我们需要输出连续的结果时，这类问题被称
为回归问题。


** 非监督学习
非监督学习的目标是自动从数据集中提取信息。整个过程没有任何人为事
先对数据集做出的假设，不添加任何先验知识。与监督学习不同，输入数
据集只包含样本的特征集，每个样本都不带有标签。非监督学习的目标是
能够自动在数据集中发现有用的信息，例如根据样本间的相似度进行聚类。
典型的应用是搜索引擎。搜索引擎的学习算法，能够通过网页间的相互引
用关系、文本内容等，自动将不同网站进行归类。当用户输入一段搜索关
键词时，算法同样可以将用户输入的指令进行归类，并将属于同一类别的
网页返回给用户。整个过程算法都没有得到任何有关类别的信息，但通过
计算样本间的相似度，算法能够自动建立样本间的联系。

非监督学习结果的好坏同样很大程度上取决于输入数据集的质量。这些算
法通过比较数据集中样本间的相似、不同之处来进行学习。下图分别举例
监督学习和非监督学习的应用场景：

#+BEGIN_QUOTE
图1.7 监督学习 v.s. 非监督学习
#+END_QUOTE

非监督学习在处理数值型数据集时具有很好的表现，但当处理非数值型数
据集时精确度会下降一些。总的来说，非监督学习适用于处理含有顺序的、
或者能够被明显划分成组的数据集。

** 强化学习
强化学习的目标是通过多次迭代、观察每次迭代后环境产生的反馈进行学
习。这类算法强调对模型输出结果所引起的外部环境反馈的交互式学习。
当模型作出正确决策时，外部环境会给予正向奖励，当出错时则会给予负
向惩罚。模型的学习目标是最大化奖励。

监督学习好比是一个老师（数据集标注者），通过标注数据在教学生（算
法）学习。然而不是在所有问题中都存在这种老师的。很多情况下，即使
人类也只能给出定性的回答（好/坏，成功/失败等）。

在这种情况下，模型只能得到每次学习结果的外部反馈，但是无法获取任
何关于优化模型（模型参数）的信息。因为我们无法针对结果定义损失函
数（cost function），也就没有梯度（gradient）供模型优化参数。强化
学习的解决办法是通过创建智能体（smart agents）在外部环境中不断试
错，来从经验中学习。

下图展示了强化学习的流程：

#+BEGIN_QUOTE
图1.8：强化学习流程展示
#+END_QUOTE


** 选择正确的算法
之前的章节中，我们学习了三类机器学习算法的异同。现在是时候回答这
个问题了：如何根据具体需求选择相应算法呢？

不幸的是，这个问题没有针对所有情形都普遍适用的答案，最好的答案可
能是：看情况。不同情况都需要考虑什么因素呢？主要需要考虑的因素来
源于数据集，包括数据集的大小、质量高低、以及样本间隐含的联系。同
时我们也需要考虑我们的任务是什么、算法是如何编写的、我们有多久的
时间去训练这些算法等等。总之，没有统一的标准，最好的办法就是从最
合适的算法开始，一一试验效果。

然而，为了理解什么是“合适的算法”，我们可以分析一些更加基础的性质。
通过分析数据集、现有的工具（算法）、任务的目标（输出结果）的基础
性质，我们能够得到许多供我们挑选算法的有用信息。

我们首先从观察数据集的性质开始讲起。我们可以从两个不同角度进行观
察：输入和输出

- 根据输入分类
  - 监督学习：输入数据中的样本既有特征矩阵，也有标签集
  - 无监督学习：输入数据中没有标签集，我们希望得到数据集中样本间
    的某种关系
  - 强化学习：输入数据是通过与外界互动迭代式积累的，我们希望在迭
    代、与环境交互中优化目标函数
- 根据输出分类
  - 回归问题：输出是连续的数值
  - 分类问题：输出是离散的类型（标签）
  - 聚类问题：输出结果是输入样本组成的一些簇

下图展示了以上两种视角：（这块干脆去了算了）

#+BEGIN_QUOTE
图1.9：基础分析 （这图没意义）
#+END_QUOTE

在了解数据集的基本性质的基础上，我们可以进一步根据我们已有的工具、
算法，分析哪些算法适用于我们的输入数据集，能够给出我们想要的输出
结果，从而缩小目标算法范围。

在我们了解了数据集、有了明确的算法范围后，我们需要训练这些算法、
评估各个算法的表现。通过一系列衡量算法表现的指标，我们能够对这些
算法进行比较，从而最终选出最合适的算法。

** 如何逐步构建机器学习模型
现在我们已经了解了挑选算法的标准、步骤，现在是时候学习如何实现机
器学习算法了。需要注意的是，下面的步骤中，除了模型实现部分，对数
据集的预处理、执行结果的评估同样至关重要：

1. 收集数据：切记，机器学习领域，数据集质量的高低直接决定结果好坏。
   比较困扰的可能是如何获取这些数据。实践中，这些数据获取可能需要
   经过相当多的步骤，例如很多数据是通过一对一的面试得到的。无论如
   何，在收集数据的过程中一定要注意选取合适的形式保存记录（例如数
   据库），以利于接下来的分析

   #+BEGIN_QUOTE
   TIP: 如果我们没有特别需求，现在互联网上已经存在了大量的公开数据。
   例如一个非常大的机器学习数据集是UCI（加州大学尔湾分校）Machine
   Learning Repository：http://archive.ics.uci.edu/ml
   #+END_QUOTE

   下图展示构建机器学习模型的步骤：

   #+BEGIN_QUOTE
   图1.10：机器学习构建流程
   #+END_QUOTE

2. 准备数据：在收集数据后，我们需要对原始数据进行一些处理。例如，
   我们很可能需要根据模型的输入数据限制，调整数据集的数据类型（例
   如整型、字符串类型；数据去量纲化等）。接下来我们会专门介绍这些
   技巧，但是预处理数据一般而言有固定的模式可循，要比收集数据简单

3. 观察数据：至此，我们需要对数据集进行观察，例如确保数据是准确的、
   没有缺失值等。我们常常使用各种类型的图表（柱状图、散点图、多维
   图表等）辅助观察。一般情况下，在这步我们已经能够对数据集的基本
   性质、样本间所蕴含的模式、联系进行粗略判断

   #+BEGIN_QUOTE
   5、6、7并不是经典方法。理论上应该分为 training validation testing
   这三步。书中6、7的解释几乎混淆
   #+END_QUOTE

4. 训练(training)算法：至此，我们真正开始处理机器学习模型相关内容。
   在这步中，我们需要对模型（目标函数、限制条件）进行定义，并采取
   某种优化算法对模型参数在输入数据集中进行求解。这些概念在后面的
   章节会具体阐释。需要指出的是，训练阶段仅仅存在于监督学习中，对
   于非监督学习而言是不存在训练阶段的，因为非监督学习的输入数据中
   没有标签、无从训练

5. 测试(testing)算法：这步开始真正刺激的环节——我们将训练得到的算
   法应用到外部的、新添加的、模型没有见过的数据集上，看模型是否真
   的有效。测试的目标是评估训练得到的模型在多大程度上逼近了真实分
   布。对于监督学习，我们有样本的标签来帮助我们衡量结果。对于非监
   督学习，我们可能需要借助其他指标来进行衡量。无论哪种情况，如果
   模型没有达到预期效果，我们都将返回步骤4，进行更改、重新训练模
   型，并对新结果继续测试

6. 评估（evaluating）算法：在此步骤中我们通过将模型应用到真实数据
   集上，来评估整个算法流程的逼近效果

7. 改进模型：至此，我们已经验证过模型确实有效、了解了模型的表现，
   现在需要更行我们对模型、问题的理解，并试图基于已有信息作出进一
   步改进

** MATLAB中的机器学习支持简介
我们已经具备了对机器学习的基本了解：机器学习的任务是什么、都有哪
类算法、如何挑选算法以及构建算法的步骤。现在我们终于可以开始学习
如何使用MATLAB实现这些了。

使用MATLAB建立机器学习模型极其方便。MATLAB提供了非常强大的交互式
界面、丰富的函数算法库、各种封装完善的APP来帮助我们应用机器学习算
法，例如：

#+BEGIN_QUOTE
这里涉及到MATLAB的专用名词，帮助文档、程序中也是这么用的，不翻译
为好
#+END_QUOTE

- 'cluster'、'classi'和'regress'算法
- Neural network（神经网络） APP、曲线拟合（curve fitting）APP
  和分类器（Classification Learner）APP 

MATLAB是专为科学计算编写的软件平台，其中，计算、可视化、编程等步
骤都被精心集成在十分易于使用的开发环境中。MATLAB的语言涉及十分贴
近数学公式本身，非常便于快速开发科学计算软件。

MATLAB名称由MATrix LABoratory（矩阵实验室）得来。MATLAB最初编写的
目标是为了方便线性代数、矩阵操作，近年来快速添加了科学计算各个领
域的丰富内容。MATLAB语言、开发环境设计本身是基于矩阵运算的，它非
常善于快速编写、验证模型，可视化数据等工作。其优秀的图形界面设计
极大有利于我们加深对数据集的理解。

MATLAB开发环境如下图所示：

#+BEGIN_QUOTE
图1.11 MATLAB开发环境
#+END_QUOTE

MATLAB尤其以其丰富、强大、精确、高质量的工具箱（函数库）著称。这
些工具箱是由一个个MATLAB函数组成的，这些工具箱涵盖了诸多领域，对
很多实际问题、模型、算法都封装了专门的函数以供用户方便地调用。

MATLAB有两个专门为机器学习算法编写的工具箱，它们是：'smltb'和
'nntb'。第一个工具箱更专注于基于概率论、统计理论的模型算法，第二
个工具箱是专门为'anns'编写的。在接下来的章节中，我们会逐个介绍这
些工具箱的强大功能。

#+BEGIN_QUOTE
图1.12：一些MATLAB中封装的APP展示
#+END_QUOTE

** 操作系统、硬件平台要求
为能够高效执行，MATLAB对计算机的软硬件有一些要求。MATLAB可以运行
在各个主流操作系统上，例如Linux、macOS和Windows。绝大多数近年的笔
记本都足够运行MATLAB。

Windows平台上安装MATLAB的要求有：

- 操作系统：Windows 10, Windows 8.1, Windows 8, Windows 7 Service
  Pack 1, Windows Server 2016, Windows Server 2012 R2, Windows
  Server 2012, and Windows Server 2008 R2 Service Pack 1
- 处理器：如何 Intel 或者 AMD 的 x86-64 架构的处理器；推荐支持
  AVX2指令集的处理器；推荐使用4核及以上处理器
- 磁盘空间：MATLAB需要4-6GB的安装空间、2GB的运行空间
- 内存：最低要求2GB；如果使用Simulink，需要4GB；Polyspace用户推荐
  每核拥有4GB可用内存
- 显卡：对显卡没有明确要求；推荐使用支持 OpenGL 3.3、拥有1GB显存
  的GPU加速卡

#+BEGIN_QUOTE
TIP 以下网站可以查询更加详细的MATLAB要求：
https://www.mathworks.com/support/sysreq.html
#+END_QUOTE



下图列举了Windows平台的安装要求：（这块干脆去了算了）

#+BEGIN_QUOTE
图1.13 Windows安装要求 （这图没意义）
#+END_QUOTE

** MATLAB安装要求
安装MathWorks公司（开发MATLAB的公司）的产品都要求一个通过购买，或
申请试用后下载获得的有效的软件版权许可证。为从官网下载，我们必须
拥有一个MathWorks公司的账户（很多大学都已经为学生购买了教育版）或
者重新注册一个。

一旦我们下载了MathWorks安装向导，我们就可以通过运行安装向导选择我
们想要安装的产品。运行安装向导的要求是：

- MathWorks账号的email地址和密码，我们在安装时需要登录账户
- 安装相关产品的许可证。如果你的许可证有问题，请咨询系统管理员
- 安装过程中可能需要关闭杀毒软件和网络防火墙，这些软件可能造成安
  装失败或降低安装速度

安装过程中遵循安装向导的指示，安装结束后我们就有一个能够运行的
MATLAB了。

#+BEGIN_QUOTE
TIP 更多安装过程信息参加官网：
https://www.mathworks.com/help/install/index.html
#+END_QUOTE

** 统计机器学习工具箱
统计机器学习工具箱包含几乎所有常用算法，其中的函数、APP集成了分析、
描述、建模等功能，并且提供了丰富的统计数据和图表用来帮助用户了解
数据集。此外，拟合概率分布、生成随机数据、假设检验等功能也得到了
强大的支持。最重要的，通过调用回归、分类工具箱我们能够轻松对数据
集进行拟合、预测。

对于数据挖掘任务，工具箱提供了特征选择、逐步回归、主成分分析
(Principal Component Analysis, PCA)、正则化、降维等用于数据变换的
函数支持。

工具箱同时支持了流行的监督学习、非监督学习模型，包括支持向量机
(Support Vector Machines, SVMs)、决策树（decision trees）、K-邻近
算法 (k-Nearest Neighbor, KNN）、K-邻近样本中心算法（k-medoids）、
层次聚类（hierarchical clustering）、高斯混合模型(Gaussian
Mixture Models, GMM）和隐马尔科夫模型(hidden Markov Models, HMM）。
MATLAB对上述函数都针对大数据进行了内存、速度上的优化。下图展示了
MATLAB官网对'smltb'的内容展示：

#+BEGIN_QUOTE
图1.14：'smltb'功能展示
#+END_QUOTE

以下是对工具箱中关键模型、功能的简介：

- 回归问题：包含对线性、广义线性、非线性、鲁棒性、正则化等回归问
  题，以及方差分析（Analysis of Variance, ANOVA）、repeated
  measures、mixed-effects等模型的支持
- 大数据支持：包含对降维算法、描述性统计值数据表、k-means聚类、线
  性回归、逻辑回归(logistic regression）、判别分析
  （discriminant analysis）的支持
- 多变量、单变量概率分布，随机和准随机（quasi-random）数据生成，
  马尔科夫链抽样
- 多种假设检验；实验设计方法：包括优化、阶乘、响应曲面设计
- 分类器APP：包含SVMs、decision trees、KNN、朴素贝叶斯（Naive
  Bayes）、判别分析、高斯过程回归
- 非监督学习：包含k-means、k-medoids、hierarchical clustering、
  GMMs和HMMs
- 基于贝叶斯方法的机器学习模型超参数（hyper-parameters）优化

下图展示了'smltb'可用资源：

#+BEGIN_QUOTE
图1.15：'smltb'可用资源
#+END_QUOTE

#+BEGIN_QUOTE
TIP：更多关于'smltb'的简介参见：
https://www.mathworks.com/products/statistics.html
#+END_QUOTE

*** 数据类型
在我们讨论'smltb'之前，我们首先应该了解MATLAB是如何处理数据
的。'smltb'只支持集中特定的数据类型作为输入变量。如果错误选用数据
类型，MATLAB可能会报错、或者返回错误结果。

*** 支持的数据类型 
- 单、双精度(single or double precision)的数值型标量（scalars）、
  向量（vectors）、矩阵（matrix）或数组（array）
- 由字符向量组成的（character vector) ~cell~ array（元胞数组）；
  character(字符)、logical（逻辑类型）或categorical（分类类型）
  array数组。这些数据类型可以存储 ~cellstr~（元胞字符串）、
  ~char~（字符）、 ~logical~ 、 ~categorical~ 、 ~num~ （数值型）
  数据
- 一些函数支持tabular array（表格类数组）；~table~（表格类型）可以
  存储上面介绍的任意数据类型
- 一些添加了GPU加速支持的函数支持 ~gpuArray~（GPU数组）

*** 不支持的数据类型
- 复数
- 自定义数据类型
- ~signed~（有符号类型）和 ~unsigned~（无符号类型）数值整型，例
  如 ~unint8~ 和 ~int16~
- sparse matrix（稀疏矩阵）；应用时，sparse matrix需要使用 ~full~
  函数被转化为 ~matrix~ 类型


** 'smltb'功能简介
在之前的章节中，我们分析'smltb'的主
要功能，以及支持的数据类型。本节将着重讲述工具箱中重要的函数，并
以实际应用场景进行举例。

*** 数据挖掘与数据可视化
数据挖掘是指发现数据集中隐含的关系、模式等有用信息。通过这个过程，
我们能够从多种角度分析数据集并提取有用信息。这些信息有助于我们之
后更好的理解我们的任务、挑选模型算法以及改进结果。

MATLAB提供了许多数据挖掘函数。'smltb'集成了多种描述数据集的函数，
例如：

- 绘制交互式统计数据图表的图形界面
- 针对大数据优化的，描述性统计数据函数

下图是一个多元数据集的统计数据图：

#+BEGIN_QUOTE
图1.16 可视化多元数据集
#+END_QUOTE

MATLAB集成了许多描述性统计信息相关的图表，并且提供了交互式图形界
面以方便我们绘制、修改。'smltb'提供了概率分布图（probability
plots）、箱状图 （box plots）、柱状图（histograms）、散点柱状图
（scatter histograms）、三维柱状图（3D histograms）、控制图
（control charts）、分位图（quantile-quantile plots）等。对于多元
变量的绘制，还提供了额外的树状聚类图（dendrograms）、双标图
（biplots）、并行坐标图（parallel coordinate charts）、安德烈图
（andrew plots）等支持。

在一些情形中，我们必须对多元变量（multivariate）进行可视化。许多
统计分析算法都要求有两个输入变量：自变量（predictor variable,
independent variable）和因变量（dependent variable，response
variable）。当这两种变量都是一维变量时，它们之间的关系很容易用二
维散点图、柱状图、箱状图等表示。相似的图表也很容易扩展到三维的情
况。然而，对于许多包含高维变量的数据集，可视化会变得困难许多。
MATLAB中添加了许多对高维变量可视化的支持，如图1.16所示。

最后，我们简要介绍下描述性统计数据功能。描述性统计功能囊括了一系
列用于描述、展示、总结数据集统计特性的统计指标。'smltb'中包含以下
指标：

- 集中趋势（central tendency）：平均数（mean）、中位数（median）、
  众数（mode）等
- 弥散度（dispertion）：向量极值的差（range）、方差（variance）、
  标准差（standard deviation）以及平均数、众数绝对离差（mean /
  median absolute deviation）
- 线性、秩和相关系数（linear/rank correlation）
- 缺失值处理
- 分位数（quantile）和百分位数（percentile）
- 基于核方法的概率密度函数估计（kernel density estimation）

*** 回归分析
回归分析常被用于拟合连续变量间的关系。其目的是建立一个由自变量到
隐变量的函数映射关系。'smltb'中包含
如下模型支持：

- 线性回归（Linear regression）
- 非线性回归（Nonlinear regression）
- 广义线性回归（Generalized linear models）
- 混合效应方程（Mixed-effects models）

下图是线性回归拟合的展示图：

#+BEGIN_QUOTE
图1.17：线性回归方程及样本散点图
#+END_QUOTE

散点图非常有助于理解变量间的联系。上图中，横坐标显示的是
自变量 $X$ ，纵坐标显示的是因变量 $Y$ 。通过回归模型，我们能够拟
合两遍量间的变化关系。如图1.17所示，简单的线性方程足以拟合线性关
系明显的样本集。

*** 分类分析
分类模型属于监督学习中的一大类模型。它们的任务是预测给定样本的类
别信息。'smltb'提供了许多参数估计、
非参数估计的分类算法，例如：

- 逻辑回归(Logistic regression)
- 决策树（包括Boosted and bagged decision trees, AdaBoost,
  LogitBoost, GentleBoost和 RobustBoost）
- 朴素贝叶斯(Naive Bayes)分类 
- KNN分类 
- 判别分析(Discriminant analysis), 线性(linear)和二次型(quadratic)
- 'svm' ('bc'和'mc')

Classification Learner APP提供了用于交互式浏览数据集、选取特征值
(select featrues)、配置交叉验证（cross-validation）参数、训练模型
参数、评估结果等任务的图形界面，包含如下功能：

- 导入数据
- 浏览数据、选择特征值
- 训练模型
- 设定交叉验证（cross-validation）参数
- 生成可共享的模型训练结果（例如计算机视觉、信号处理工具箱允许的
  格式）
 
通过使用Classification Learner APP，我们能够非常方便的训练模型。
训练完成后，每次迭代的训练结果会被展示出来，以供用户挑选表现最好
的模型、参数组合。

下图是Classification Learner APP展示：

#+BEGIN_QUOTE
图1.18：Classification Learner APP截屏，及训练结果展示
#+END_QUOTE

*** 聚类分析
聚类分析是无监督学习的一大类方法。笼统的说，聚类学习的目标是通过
观察数据集中的统计特征，通过计算以某种形式定义的 *距离* 的概念，
通过最小化簇内距离、最大化簇间距离，实现对数据集的自动聚类。聚类
分析中的距离常使用相似度、离散度、信息熵等统计学指标进行定义。

'smltb'包含以下聚类算法支持：

- K-均值算法（k-means）
- K-邻近样本中心算法（k-medoids）
- 层次聚类(Hierarchical clustering)
- 高斯混合模型（GMM）
- 隐马尔科夫模型（HMM）

当聚类中心的数量不明确时，我们可以自定义特定聚类中心度量指标进行
聚类。

下图展示了聚类算法：

#+BEGIN_QUOTE
图1.19：聚类算法展示
#+END_QUOTE

除此之外，'smltb'提供了树状聚类图（dendrogram）来展示层次聚类结果。
因此我们可以很方便地通过调整叶节点顺序来改善聚类效果。此外我们还
可以对高维向量绘制树状聚类图（dendrogram）。

*** 降维分析
降维分析是指将高维矩阵变化到低维矩阵，同时尽量最大程度保留原有信
息的过程。降维方法能够减少数据中的冗余信息、改进模型预测结果、提
高模型可理解程度（降低模型复杂度）以及避免过拟合
（over-fitting）。'smltb'集成了多种降维算法。这些算法可以被分为特
征提取（feature extraction）和特征选择（feature selection）两类。
特征选择（feature selection）方法试图选取原特征矩阵中的一组子集来
代表整体数据集。特征提取（feature extraction）方法则试图通过降维、
矩阵变换等方法将原有特征矩阵去除冗余信息并生成新的特征矩阵。

工具箱对特征选择（feature selection）提供如下支持：

- 逐步回归（step-wise regression）: 逐步添加特征值直到模型预测
  结果不因添加更多特征值而更好时停止，停止时选取的特征值组合就是
  选取的子集。这种方法尤其适合线性回归和广义线性回归算法
- 顺序化特征选择（Sequential feature selection）：相当于专为普遍适
  用监督学习而改进的的逐步回归算法
- 决策树：使用决策树选择特征值
- 正则化（Regularization）: 通过调整特征值权重去除冗余信息

此外，工具箱还添加了对特征提取（feature extraction）算法的支持：

- 主成分分析法（PCA）: 通过正交变换将一组可能存在相关性的变量转换
  为一组线性不相关的变量
- 因子分析（Factor analysis）: 将众多原始变量变换为少数几个因子，
  并对因子变量进行归类、提高其可解释性
- 非负矩阵分解（Non-negative matrix factorization）: 此算法可用于
  结果中不能有负值的降维任务中

下图展示了逐步回归结果：

#+BEGIN_QUOTE
图1.20：逐步回归结果展示
#+END_QUOTE


** Neural Network Toolbox神经网络工具箱
'anns'是受人脑启发，以多层、每层多个人工神经元（artificial
neurons）构成的网络模型。每个神经元与相邻层的神经元都有多个输入、
输出的链接，并将输入加总后执行激活函数（activate function）的运
算。'anns'能够通过学习数据集、优化大量参数，对复杂问题进行有效拟
合，非常适合应用于传统计算机算法无法明确表述、非常复杂的问题。

神经网络(Neural Network)工具箱提供了优化算法，预训练（pre-trained）
网络，以及用于构建、训练、可视化和仿真的图形界面。通过应用这些工
具，我们能够方便地解决分类、回归、聚类、降维、时间序列预测、动态
系统建模以及控制问题。

拥有少数几层隐含层（hidden layer）的神经网络被称为浅层神经网络
(shallow neural networks)，拥有多层隐含层的神经网络被称为深度神经
网络（deep neural networks）。深度神经网络包括卷积神经网络
(convolutional neural networks, CNN）、自编码器（auto-encoders）
等，适用于分类、回归及特征学习问题。对于中等规模的数据集，我们可
以通过迁移学习（transfer learning）的方式，使用MATLAB自带的预训练
(pre-trained)网络，节省训练连时间、改善预测结果。对于大数据，我们
可以应用MATLAB提供的并行计算工具箱（Parallel Computing Toolbox）
利用GPU加速网络训练。通过分布式计算服务器（MATLAB Distributed
Computing Server），我们可以将计算任务分配到集群中的各个节点进一
步加速。

'nntb'主要涵盖了一下功能：

- 基于CNN（用于分类和回归）、auto-encoders（用于特征值学习）的深
  度学习模型
- 基于预训练CNNs和Caffe model zoo（Caffe是深度学习领域最流行的框
  架之一，model zoo是caffe的模型库）的迁移学习（transfer learning）
- 基于单节点、集群、云的多CPU、GPU训练、预测算法
- 非监督学习算法，包括自组织映射网络(self-organizing maps，SOM）
  和竞争层（competitive layers）

下图展示了MATLAB官网对'nntb'介绍的截图：

#+BEGIN_QUOTE
图1.21 'nntb'功能展示
#+END_QUOTE 

- 监督学习算法，包括学习矢量量化神经网络(Learning Vector
  Quantization, LVQ),非线性自回归神经网络 (nonlinear
  auto-regressive, NARX), 和循环神经网络(Recurrent Neural
  Network, RNNs)
- 用于数据拟合、模式识别和聚类的APP
- 数据集、神经网络的预处理、可视化、参数调优图形界面

#+BEGIN_QUOTE
TIP 更详细的信息请参见官网工具箱说
明:https://www.mathworks.com/products/%20neural-network.html
#+END_QUOTE

** MATLAB中的统计学和线性代数
机器学习是由统计学、概率论、代数、计算机科学等诸多学科组成的交叉
学科。这些交叉学科的理论赋予了机器学习算法从原始数据集中迭代式学
习、寻找样本间的隐藏模式以及构建智能应用的能力。尽管机器学习算法
直接提供了强大的学习能力，了解这些算法背后其它学科的理论支撑能够
极大加深我们对算法的理解和应用能力。

机器学习中统计学、概率论和代数知识的重要性体现在以下几点：

- 根据特征值数量、训练时间、参数个数模型复杂度以及任务要求的精度
  选取适当算法
- 配置验证算法（validation）参数，设置模型的'hp'
- 发现过拟合（over-fitting）及拟合不足（under-fitting）问题
- 设置合理的置信区间

MATLAB对统计分析、线性代数运算提供了很多函数支持。例如，使用
MATLAB计算描述性统计数据非常简单。MATLAB自带了集中趋势（central
tendency）、弥散度（dispertion）、分位数（quantiles）等诸多指标。
此外，我们还可以建立表单数据（tabulate）和跨表单数据
（cross-tabulate），并且对分组后的数据计算描述性统计指标。

值得注意的是，MATLAB语法规定，任何对 ~NaN~ （MATLAB中表示空值的关
键字）的数值运算都将返回 ~NaN~ 。'smltb'中的函数对 ~NaN~ 进行了特
殊优化。当输入数据中包含 ~NaN~ 时，这些函数将忽略空值，直接使用非
空值数据进行计算。

更强大的是，MATLAB提供了非常方便的可视化工具帮助我们可视化数据集
的统计特征、分布特征，并能够与其它数据集、概率分布进行比较。我们
不止可以对一元问题绘制散点图、箱状图、柱状图，对二元问题同样可以
绘制这些图表。对于多元问题，我们可以通过绘制多张图表、安德烈图
（andrews）、星状图、人脸图（glyphs）等方法进行描述。最后我们还可
以在图上内嵌定制化的最小二乘线（least-squares）、辅助线和注释等信
息。

对于线性代数，MATLAB提供了非常多的函数支持。线性代数是对矩阵进行
线性运算的学科。MATLAB提供了丰富且极易使用的矩阵操作运算支持。

#+BEGIN_QUOTE
图1.22：使用柱状图进行概率密度函数估计
#+END_QUOTE

MATLAB对如下功能提供函数支持：

- 矩阵操作和矩阵变换
- 线性方程
- 矩阵分解
- 特征值和特征向量
- 矩阵分析和向量运算
- 正则化运算及其它矩阵运算
- 矩阵方程

有了这些支持，在MATLAB中进行线性代数操作变得极为简单。

** 总结
本章我们领略了机器学习世界的强大功能，并学习了几种主流算法及其适
用情景。同时我们也学习了许多帮助理解数据集的技巧，并展示了如何构
建机器学习模型需要的步骤。

接着我们将视线转移到了MATLAB，我们介绍了MATLAB的安装须知。并强调
了MATLAB在机器学习领域，如分类、回归、聚类和深度学习，的诸多支持，
包括自动建模和代码生成。

最后，我们对'smltb'和'nntb'进行了着重介绍。我们展示了其中包含的工
具，以及这些工具的适用场景。我们也展示了统计学和代数学在机器学习
中的重要作用以及MATLAB的相关支持。

下一章中，我们将学习如何使用MATLAB的workspace（工作空间）、如何导
入导出数据和如何根据使用需求整理数据到特定格式。





